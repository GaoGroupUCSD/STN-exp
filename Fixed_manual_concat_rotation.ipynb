{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments by concating rotated filters of CNN layer: 90/45 degrees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# debug flag to test if the implementation is correct\n",
    "debug = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "permutation = [[1, 0], [0, 0], [0, 1], [2, 0], [1, 1], [0, 2], [2, 1], [2, 2], [1, 2]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train sample:', (3600,))\n",
      "Train samples: (50000, 60, 60, 1)\n",
      "Validation samples: (10000, 60, 60, 1)\n",
      "Test samples: (10000, 60, 60, 1)\n",
      "('output shape:', (50000, 10))\n",
      "('Input shape:', (60, 60, 1))\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "\n",
    "DIM = 60\n",
    "mnist_cluttered = \"datasets/mnist_cluttered_60x60_6distortions.npz\"\n",
    "\n",
    "# Preparing data\n",
    "data = np.load(mnist_cluttered)\n",
    "X_train, y_train = data['x_train'], np.argmax(data['y_train'], axis=-1)\n",
    "print(\"X_train sample:\", X_train[0].shape)\n",
    "X_valid, y_valid = data['x_valid'], np.argmax(data['y_valid'], axis=-1)\n",
    "X_test, y_test = data['x_test'], np.argmax(data['y_test'], axis=-1)\n",
    "# reshape for convolutions\n",
    "X_train = X_train.reshape((X_train.shape[0], DIM, DIM, 1))\n",
    "X_valid = X_valid.reshape((X_valid.shape[0], DIM, DIM, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], DIM, DIM, 1))\n",
    "#one hot\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(\"Train samples: {}\".format(X_train.shape))\n",
    "print(\"Validation samples: {}\".format(X_valid.shape))\n",
    "print(\"Test samples: {}\".format(X_test.shape))\n",
    "\n",
    "print(\"output shape:\", y_train.shape)\n",
    "input_shape =  np.squeeze(X_train.shape[1:])\n",
    "input_shape = (DIM, DIM, 1)\n",
    "print(\"Input shape:\",input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAG2CAYAAADfkJmbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nztSyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f91ac407a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(X_train[101].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "plt.title('Cluttered MNIST', fontsize=20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras import layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the rotation function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Sanity check shift_rotate implementation\n",
    "\"\"\"\n",
    "\n",
    "if(debug):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "\n",
    "    w = np.array(\n",
    "        [\n",
    "            [\n",
    "                [\n",
    "                    [1, 2, 3],\n",
    "                    [4, 5, 6],\n",
    "                    [7, 8, 9]\n",
    "                ],\n",
    "                [\n",
    "                    [11, 22, 33],\n",
    "                    [44, 55, 66],\n",
    "                    [77, 88, 99]\n",
    "                ],\n",
    "                [\n",
    "                    [111, 222, 333],\n",
    "                    [444, 555, 666],\n",
    "                    [777, 888, 999]\n",
    "                ]\n",
    "            ],\n",
    "            [\n",
    "                [\n",
    "                    [1, 2, 3],\n",
    "                    [4, 5, 6],\n",
    "                    [7, 8, 9]\n",
    "                ],\n",
    "                [\n",
    "                    [11, 22, 33],\n",
    "                    [44, 55, 66],\n",
    "                    [77, 88, 99]\n",
    "                ],\n",
    "                [\n",
    "                    [111, 222, 333],\n",
    "                    [444, 555, 666],\n",
    "                    [777, 888, 999]\n",
    "                ]\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    w = np.moveaxis(w, (2, 3), (0, 1))\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    # shape: (row, col, inp_nb, out_nb) -> (3, 3, 2, 3)\n",
    "    w = tf.constant(w)\n",
    "\n",
    "    w1 = shift_rotate(w, 4)\n",
    "    print w1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(convs):\n",
    "    if convs is None:\n",
    "        convs = [conv_old, conv_old, conv_old, conv_old]\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(convs[0](32, (3, 3), padding='same', input_shape=input_shape, use_bias=False, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(convs[1](32, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(convs[2](32, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(convs[3](32, (3, 3), use_bias=False, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to rotate the filters and new convolution layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shift times according to the parameter shift\n",
    "def shift_rotate(w, shift=1):\n",
    "    shape = w.get_shape()\n",
    "    for i in range(shift):\n",
    "        #tf.gather_nd gathers the values according to the indices specified in permutation.\n",
    "        w = tf.reshape(tf.gather_nd(w, permutation), shape)\n",
    "    return w\n",
    "\n",
    "#new convolution class which does convolution using 4 rotations\n",
    "class Convolution2D_4(Conv2D):\n",
    "    def call(self, x, mask=None):\n",
    "        w = self.weights[0]\n",
    "        w_rot = [w]\n",
    "        # shifts of 90 degrees everytime\n",
    "        for i in range(3):\n",
    "            w = shift_rotate(w, shift=2)\n",
    "            w_rot.append(w)\n",
    "        \n",
    "        # convolves all the 4 filters on the input image.\n",
    "        outputs = tf.concat([K.conv2d(x, w_i, strides = self.strides,\n",
    "                                     padding=self.padding,\n",
    "                                     data_format=self.data_format,\n",
    "                                    ) for w_i in w_rot], -1)\n",
    "        filter_size = 5\n",
    "        output = tf.reshape(outputs, [-1, filter_size, filter_size, self.filters*4])\n",
    "        \n",
    "        if self.use_bias:\n",
    "            if self.data_format == 'channels_first':\n",
    "                output += K.reshape(self.use_bias, (1, self.filters, 1, 1))\n",
    "            elif self.data_format == 'channels_last':\n",
    "                output += K.reshape(self.use_bias, (1, 1, 1, self.filters))\n",
    "            else:\n",
    "                raise ValueError('Invalid dim_ordering:', self.data_format)\n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        filter_size = 5\n",
    "        output_shape = (-1, filter_size, filter_size, self.filters*4)\n",
    "        return output_shape\n",
    "\n",
    "\n",
    "class Convolution2D_8(Conv2D):\n",
    "    def call(self, x, mask=None):\n",
    "        w = self.weights[0]\n",
    "        \n",
    "        w_rot = [w]\n",
    "        for i in range(7):\n",
    "            w = shift_rotate(w)\n",
    "            w_rot.append(w)\n",
    "\n",
    "        outputs = tf.concat([K.conv2d(x, w_i, strides = self.strides,\n",
    "                                     padding=self.padding,\n",
    "                                     data_format=self.data_format,\n",
    "                                    ) for w_i in w_rot], -1)\n",
    "        filter_size = 5\n",
    "        output = tf.reshape(outputs, [-1, filter_size, filter_size, self.filters*8])\n",
    "        if self.use_bias:\n",
    "            if self.data_format == 'channels_first':\n",
    "                output += K.reshape(self.use_bias, (1, self.filters, 1, 1))\n",
    "            elif self.data_format == 'channels_last':\n",
    "                output += K.reshape(self.use_bias, (1, 1, 1, self.filters))\n",
    "            else:\n",
    "                raise ValueError('Invalid dim_ordering:', self.data_format)\n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        filter_size = 5\n",
    "        output_shape = (-1, filter_size, filter_size, self.filters*8)\n",
    "        return output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(run_name, model, nb_epochs, X_train, y_train, X_valid, y_valid):\n",
    "    maxVAcc = maxTAcc = maxVScore = maxTScore = epoch = 0\n",
    "    for e in range(nb_epochs):\n",
    "#         print('-'*40)\n",
    "#         progbar = generic_utils.Progbar(X_train.shape[0])\n",
    "        for b in range(150):\n",
    "#             print(b)\n",
    "            f = b * batch_size\n",
    "            l = (b+1) * batch_size\n",
    "            X_batch = X_train[f:l].astype('float32')\n",
    "            y_batch = y_train[f:l].astype('float32')\n",
    "            loss = model.train_on_batch(X_batch, y_batch)\n",
    "#             print(loss)\n",
    "#             progbar.add(X_batch.shape[0], values=[(\"train loss\", loss)])\n",
    "        scorev, accv = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "        scoret, acct = model.evaluate(X_test, y_test, verbose=1)\n",
    "        if(maxTAcc < acct):\n",
    "            maxTAcc = acct\n",
    "            maxVAcc = accv\n",
    "            maxVScore = scorev\n",
    "            maxTScore = scoret\n",
    "            epoch = e\n",
    "        if(e%1==0):\n",
    "            print('Epoch: {0} | Valid Score: {1}| Test Score: {2}| Valid Acc: {3} | Test Acc: {4}'.format(e, scorev, scoret, accv, acct))\n",
    "    return maxVAcc, maxTAcc, maxVScore, maxTScore, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_rot_1st\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_84/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-1ff13159990b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m#make the model parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-3f78b22adaae>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(convs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    490\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[0;32m    491\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    156\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                                         data_format=self.data_format)\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36m_pooling_function\u001b[1;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[0;32m    219\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[0;32m    220\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m                           pool_mode='max')\n\u001b[0m\u001b[0;32m    222\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mpool2d\u001b[1;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[0;32m   3652\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[0;32m   3653\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3654\u001b[1;33m                            data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3655\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'avg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3656\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   1767\u001b[0m                                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1768\u001b[0m                                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1769\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m   1770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36m_max_pool\u001b[1;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   1603\u001b[0m   result = _op_def_lib.apply_op(\"MaxPool\", input=input, ksize=ksize,\n\u001b[0;32m   1604\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   1606\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1874\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_84/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,32]."
     ]
    }
   ],
   "source": [
    "from keras.utils.training_utils import multi_gpu_model\n",
    "conv_8 = Convolution2D_8\n",
    "conv_old = Conv2D\n",
    "conv_4 = Convolution2D_4\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Cleanup old weight dir.\n",
    "    import os, shutil\n",
    "    shutil.rmtree('weights', ignore_errors=True)\n",
    "    os.makedirs('weights')\n",
    "\n",
    "#     names = ['8_rot_4', '8_rot_3', '8_rot_2', '8_rot_1', '4_rot_4', '4_rot_3', '4_rot_2', '4_rot_1']#, 'baseline']\n",
    "    names = ['8_rot_1st','8_rot_2nd','8_rot_3rd', '4_rot_1st', '4_rot_2nd','4_rot_3rd', 'baseline']\n",
    "\n",
    "    convs = [\n",
    "#        [conv_8, conv_8, conv_8, conv_8],\n",
    "#         [conv_old, conv_8, conv_8, conv_8],\n",
    "#         [conv_old, conv_old, conv_8, conv_8],\n",
    "#         [conv_old, conv_old, conv_old, conv_8],\n",
    "        \n",
    "        [conv_8, conv_old, conv_old, conv_old],\n",
    "        [conv_old, conv_8, conv_old, conv_old],\n",
    "        [conv_old, conv_old, conv_8, conv_old],\n",
    "#         [conv_4, conv_4, conv_4, conv_4],\n",
    "#         [conv_old, conv_4, conv_4, conv_4],\n",
    "#         [conv_old, conv_old, conv_4, conv_4],\n",
    "        [conv_4, conv_old, conv_old, conv_old], \n",
    "        [conv_old, conv_4, conv_old, conv_old], \n",
    "        [conv_old, conv_old, conv_4, conv_old], \n",
    "\n",
    "#         None\n",
    "    ]\n",
    "\n",
    "nb_epochs = 110 # you probably want to go longer than this\n",
    "batch_size = 256\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(names[i])\n",
    "    model = get_model(convs[i])\n",
    "    model.summary()\n",
    "    #make the model parallel\n",
    "#     model = multi_gpu_model(model, gpus=1)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    maxVAcc, maxTAcc, maxVScore, maxTScore, epoch = train(names[i], model, nb_epochs, X_train, y_train, X_valid, y_valid)\n",
    "    f = open('results_concat_filter_maps.txt','a') \n",
    "    f.write(\"Results for: {0}\".format(names[i]))\n",
    "    f.write('\\n')\n",
    "    f.write('maxVAcc: {0}, maxTAcc: {1}, maxVScore: {2}, maxTScore: {3}, epoch: {4}'.format( maxVAcc, maxTAcc, maxVScore, maxTScore, epoch ))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.close()\n",
    "    print('maxVAcc: {0}, maxTAcc: {1}, maxVScore: {2}, maxTScore: {3}, epoch: {4}'.format( maxVAcc, maxTAcc, maxVScore, maxTScore, epoch ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from keras.layers import Convolution2D as conv_old\n",
    "\n",
    "\n",
    "def get_probs_matched(imgs, model, idx):\n",
    "    probs = model.predict_proba(imgs, verbose=0)\n",
    "    preds = probs.argmax(axis=-1)\n",
    "    probs = probs[:, y_test[idx][0]]\n",
    "    matched = (len(np.where(preds == y_test[idx][0])[0]) * 100.0) / len(imgs)\n",
    "    return probs, matched\n",
    "\n",
    "\n",
    "def compare(test_id, angles, models):\n",
    "    img = X_test[test_id]\n",
    "    imgs = np.array([ndimage.rotate(img, rot, reshape=False) for rot in angles])\n",
    "\n",
    "    all_probs = []\n",
    "    all_matched = []\n",
    "    for model in models:\n",
    "        probs, matched = get_probs_matched(imgs, model, test_id)\n",
    "        all_probs.append(probs)\n",
    "        all_matched.append(matched)\n",
    "\n",
    "    return all_probs, all_matched\n",
    "\n",
    "\n",
    "def plot_multi(names, models, angles, runs=1000):\n",
    "    indices = np.random.permutation(len(X_test))[:runs]\n",
    "\n",
    "    matched_all = []\n",
    "    for i, idx in enumerate(indices):\n",
    "        print(\"Processing {}/{}\".format(i, len(indices)))\n",
    "        probs, matched = compare(idx, angles, models)\n",
    "        matched_all.append(matched)\n",
    "\n",
    "    matched_all = np.array(matched_all)\n",
    "    order = np.argsort(np.mean(matched_all, axis=0))\n",
    "    df = pd.DataFrame.from_items([(names[i], matched_all[:, i]) for i in order])\n",
    "    sb.boxplot(data=df)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_single(names, models, angles, test_id):\n",
    "    all_probs, all_matched = compare(test_id, angles, models)\n",
    "    legends = []\n",
    "\n",
    "    order = np.argsort(all_matched)\n",
    "    for i in order:\n",
    "        plt.plot(angles, all_probs[i])\n",
    "        legends.append('{} {:.2f}%'.format(names[i], all_matched[i]))\n",
    "\n",
    "    plt.ylabel('Prediction probability of correct class')\n",
    "    plt.legend(legends, loc=9, bbox_to_anchor=(0.5, -0.05), ncol=len(names))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    names = ['baseline', '8_rot_4', '8_rot_3', '8_rot_2', '8_rot_1', '4_rot_4', '4_rot_3', '4_rot_2', '4_rot_1']\n",
    "    convs = [\n",
    "        None,\n",
    "        [conv_8, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_old, conv_8],\n",
    "        [conv_4, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_old, conv_4],\n",
    "    ]\n",
    "\n",
    "    models = []\n",
    "    indices = range(len(names))\n",
    "    for i in indices:\n",
    "        model = get_model(convs[i])\n",
    "        model.load_weights('./weights/{}.hdf5'.format(names[i]))\n",
    "        models.append(model)\n",
    "\n",
    "    angles = np.arange(0, 360, 1)\n",
    "    # plot_single([names[i] for i in indices], models, angles=angles, test_id=5)\n",
    "    plot_multi(names, models, angles=angles, runs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
