# Transformations of convolutional filters 

## Idea 
To transform the filters according to the input /part of the image we are convolving on at a time.

## Goal:
- decrease the number of filters, 
- increase in accuracy

## Related work:
1. Dynamic Steerable blocks in Deep Residual Networks
https://arxiv.org/pdf/1706.00598.pdf
-  able to seamlessly
transform filters under pre-defined transformations, conditioned on the input at
training and inference time.
- Dynamic steerable blocks learn the degree of invariance
from data and locally adapt filters, allowing them to apply a different geometrical variant
of the same filter to each location of the feature map. 
- 

## Experiments:
### Task:
Digit classification

### Network setup: 
<pre>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 60, 60, 32)        288       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         
_________________________________________________________________
convolution2d_8_1 (Convoluti (None, 30, 30, 32)        9216      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         
_________________________________________________________________
convolution2d_8_2 (Convoluti (None, 15, 15, 32)        9216      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
convolution2d_8_3 (Convoluti (None, 5, 5, 32)          9216      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 2, 2, 32)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               33024     
_________________________________________________________________
activation_1 (Activation)    (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                2570      
_________________________________________________________________
activation_2 (Activation)    (None, 10)                0         
=================================================================
Total params: 63,530
Trainable params: 63,530
Non-trainable params: 0
_________________________________________________________________
</pre>
#### Baseline:
- 4 CNN layers followed by maxpool
- 2 Dense layers (256 and 10 neurons)
- Dropout: 0.3 rate
- Epochs: 110
- Optimizer: Adam

### Dataset 
Cluttered MNIST

### Results
#### Experiment 1: 
#### Setup:
No of filters in each convolutional layer: 32
Rotated filter layer: Convolutional layer where every filter is rotated to 45 degrees and stacked together. The output of this layer is the element wise maximum of the convolution output.

| Model  | Validation accuracy | Test accuracy| Validation loss | Test loss
| ------------- | ------------- |-------------|-----------------|-----------|
|  Baseline  | 95.1  | 95.08 | 0.35393| 0.355747|
| All 4 conv layers with 4 rotated filters  | 89.06  | 89.35| 0.7768204 |0.7627| 
| All 4 conv layers with 3 rotated filters  | 93.9  | 93.988| 0.3137442 | 0.317178| 
| All 4 conv layers with 2 rotated filters  | 94.5  | 94.47| 0.33467211 |0.3243| 
| All 4 conv layers with 1 rotated filters  | 95.1  | 95.17|0.34857| 0.3810| 

#### Experiment 2: 
#### Setup:
No of filters in each convolutional layer: 16
Rotated filter layer: Convolutional layer where every filter is rotated to 90 degrees and stacked together. The output of this layer is the element wise maximum of the convolution output.

| Model  | Validation accuracy | Test accuracy| Validation loss | Test loss
| ------------- | ------------- |-------------|-----------------|-----------|
|  Baseline  | 95.1  | 95.08 | 0.35393| 0.355747|
| All 4 conv layers with 4 rotated filters  | 91.84 | 90.84 |0.6765 | 0.6759| 
| All 4 conv layers with 3 rotated filters  | 94.5  | 94.3| 0.3489| 0.36120| 
| All 4 conv layers with 2 rotated filters  | 94.4  | 94.49| 0.35597| 0.353036| 
| All 4 conv layers with 1 rotated filters  | 95.3 | 95.25| 0.34364 | 0.3762| 


#### Experiment 3: 
#### Setup:
- No of filters in each convolutional layer: 16
- Rotated filter layer: Convolutional layer where every filter is rotated to 45 degrees and stacked together. The output of this layer is the element wise maximum of the convolution output.

| Model  | Validation accuracy | Test accuracy| Validation loss | Test loss
| ------------- | ------------- |-------------|-----------------|-----------|
|  Baseline  | 92.92  | 92.79 | 0.3429| 0.3883|
| All 4 conv layers with 3 rotated filters  | 91.5  | 91.1| 0.3484 | 0.36384| 
| All 4 conv layers with 2 rotated filters  | 91.18  | 91.32| 0.34453 | 0.3548| 
| All 4 conv layers with 1 rotated filters  | 91.53  | 91.96| 0.543602 | 0.544| 

#### Experiment 4: 
#### Setup:
No of filters in each convolutional layer: 16
Rotated filter layer: Convolutional layer where every filter is rotated to 90 degrees and stacked together. The output of this layer is the element wise maximum of the convolution output.

| Model  | Validation accuracy | Test accuracy| Validation loss | Test loss
| ------------- | ------------- |-------------|-----------------|-----------|
|  Baseline  | 93.02  | 93.25 | 0.34501| 0.33128|
| All 4 conv layers with 3 rotated filters  | 92.8  | 93.08| 0.261119 | 0.252387| 
| All 4 conv layers with 2 rotated filters  | 92.5  | 92.09| 0.30970 | 0.3239| 
| All 4 conv layers with 1 rotated filters  | 92.9  | 92.95| 0.3904366 | 0.36607| 

### Findings
- If we use a rotated filter layer as the first convlolutional layer, the accuracy drop significantly to 3-4 points compared to the baseline
- For all the other layers, the accuracy is not very different when compared with applying the rotational convolutional layer to deeper layers.
- The accuracy with lesser rotational layers is the highest though with a marginal difference.
- The accuracy for 4 rotations is better in case of 16 filters as compared to 8 rotations.


