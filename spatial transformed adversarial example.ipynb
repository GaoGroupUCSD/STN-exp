{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatially transformed adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ipdb\n",
    "%matplotlib inline\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_data = './MNIST-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## setup_mnist.py -- mnist data and model loading code\n",
    "##\n",
    "## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import urllib\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(num_images*28*28)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data / 255) - 0.5\n",
    "        data = data.reshape(num_images, 28, 28, 1)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "    return (np.arange(10) == labels[:, None]).astype(np.float32)\n",
    "\n",
    "class MNIST:\n",
    "    def __init__(self):\n",
    "        if not os.path.exists(MNIST_data):\n",
    "            os.mkdir(MNIST_data)\n",
    "            files = [\"train-images-idx3-ubyte.gz\",\n",
    "                     \"t10k-images-idx3-ubyte.gz\",\n",
    "                     \"train-labels-idx1-ubyte.gz\",\n",
    "                     \"t10k-labels-idx1-ubyte.gz\"]\n",
    "            for name in files:\n",
    "\n",
    "                urllib.urlretrieve('http://yann.lecun.com/exdb/mnist/' + name, \"MNIST_data/\"+name)\n",
    "\n",
    "        train_data = extract_data(MNIST_data + \"//train-images-idx3-ubyte.gz\", 60000)\n",
    "        train_labels = extract_labels(MNIST_data + \"/train-labels-idx1-ubyte.gz\", 60000)\n",
    "        self.test_data = extract_data(MNIST_data + \"/t10k-images-idx3-ubyte.gz\", 10000)\n",
    "        self.test_labels = extract_labels(MNIST_data + \"/t10k-labels-idx1-ubyte.gz\", 10000)\n",
    "        \n",
    "        VALIDATION_SIZE = 5000\n",
    "        \n",
    "        self.validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "        self.validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "        self.train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "        self.train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "\n",
    "class MNISTModel:\n",
    "    def __init__(self, restore, session=None):\n",
    "        self.num_channels = 1\n",
    "        self.image_size = 28\n",
    "        self.num_labels = 10\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, (3, 3),\n",
    "                         input_shape=(28, 28, 1)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(32, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(10))\n",
    "        model.load_weights(restore)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "12416/55000 [=====>........................] - ETA: 1:09 - loss: 1.9477 - acc: 0.3228"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e97cd627b1d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models/mnist\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;31m# train_distillation(MNIST(), \"models/mnist-distilled-100\", [32, 32, 64, 64, 200, 200],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-e97cd627b1d9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data, file_name, params, num_epochs, batch_size, train_temp, init)\u001b[0m\n\u001b[0;32m     64\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m               \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m               shuffle=True)\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## train_models.py -- train the neural network models for attacking\n",
    "##\n",
    "## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "# from setup_mnist import MNIST\n",
    "# from setup_cifar import CIFAR\n",
    "import os\n",
    "\n",
    "def train(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
    "    \"\"\"\n",
    "    Standard neural network training procedure.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    print(data.train_data.shape)\n",
    "    \n",
    "    model.add(Conv2D(params[0], (3, 3),\n",
    "                            input_shape=data.train_data.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[1], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(params[2], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[3], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(params[4]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(params[5]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    \n",
    "    if init != None:\n",
    "        model.load_weights(init)\n",
    "\n",
    "    def fn(correct, predicted):\n",
    "        return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
    "                                                       logits=predicted/train_temp)\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "\n",
    "    if file_name != None:\n",
    "        model.save(file_name)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_distillation(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1):\n",
    "    \"\"\"\n",
    "    Train a network using defensive distillation.\n",
    "    Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks\n",
    "    Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, Ananthram Swami\n",
    "    IEEE S&P, 2016.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_name+\"_init\"):\n",
    "        # Train for one epoch to get a good starting point.\n",
    "        train(data, file_name+\"_init\", params, 1, batch_size)\n",
    "    \n",
    "    # now train the teacher at the given temperature\n",
    "    teacher = train(data, file_name+\"_teacher\", params, num_epochs, batch_size, train_temp,\n",
    "                    init=file_name+\"_init\")\n",
    "\n",
    "    # evaluate the labels at temperature t\n",
    "    predicted = teacher.predict(data.train_data)\n",
    "    with tf.Session() as sess:\n",
    "        y = sess.run(tf.nn.softmax(predicted/train_temp))\n",
    "        print(y)\n",
    "        data.train_labels = y\n",
    "\n",
    "    # train the student model at temperature t\n",
    "    student = train(data, file_name, params, num_epochs, batch_size, train_temp,\n",
    "                    init=file_name+\"_init\")\n",
    "\n",
    "    # and finally we predict at temperature 1\n",
    "    predicted = student.predict(data.train_data)\n",
    "\n",
    "    print(predicted)\n",
    "    \n",
    "if not os.path.isdir('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "train(MNIST(), \"models/mnist\", [32, 32, 64, 64, 200, 200], num_epochs=50)\n",
    "\n",
    "# train_distillation(MNIST(), \"models/mnist-distilled-100\", [32, 32, 64, 64, 200, 200],\n",
    "#                    num_epochs=50, train_temp=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial transformed adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## stAdv_attack.py -- attack a network optimizing for spatial distance\n",
    "##\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "BINARY_SEARCH_STEPS = 9  # number of times to adjust the constant with binary search\n",
    "MAX_ITERATIONS = 10000   # number of iterations to perform gradient descent/L-BFGS\n",
    "ABORT_EARLY = True       # if we stop improving, abort gradient descent early\n",
    "LEARNING_RATE = 1e-2     # larger values converge faster to less accurate results\n",
    "TARGETED = True          # should we target one specific class? or just be wrong?\n",
    "CONFIDENCE = 0           # how strong the adversarial example should be\n",
    "INITIAL_CONST = 1e-3     # the initial constant c to pick as a first guess, Manages the contiribution of the loss due to flow or spatial regularization loss.\n",
    "\n",
    "class STAdv:\n",
    "    def __init__(self, sess, model, batch_size=1, confidence = CONFIDENCE,\n",
    "                 targeted = TARGETED, learning_rate = LEARNING_RATE,\n",
    "                 binary_search_steps = BINARY_SEARCH_STEPS, max_iterations = MAX_ITERATIONS,\n",
    "                 abort_early = ABORT_EARLY, \n",
    "                 initial_const = INITIAL_CONST,\n",
    "                 boxmin = -0.5, boxmax = 0.5):\n",
    "        \"\"\"\n",
    "        The Spatial transformed adversarial attack. \n",
    "        This attack is the based on Spatially transformed adversarial examples paper.\n",
    "        Returns adversarial examples for the supplied model.\n",
    "        confidence: Confidence of adversarial examples: higher produces examples\n",
    "          that are farther away, but more strongly classified as adversarial.\n",
    "        batch_size: Number of attacks to run simultaneously.\n",
    "        targeted: True if we should perform a targetted attack, False otherwise.\n",
    "        learning_rate: The learning rate for the attack algorithm. Smaller values\n",
    "          produce better results but are slower to converge.\n",
    "        binary_search_steps: The number of times we perform binary search to\n",
    "          find the optimal tradeoff-constant between distance and confidence. \n",
    "        max_iterations: The maximum number of iterations. Larger values are more\n",
    "          accurate; setting too small will require a large learning rate and will\n",
    "          produce poor results.\n",
    "        abort_early: If true, allows early aborts if gradient descent gets stuck.\n",
    "        initial_const: The initial tradeoff-constant to use to tune the relative\n",
    "          importance of distance and confidence. If binary_search_steps is large,\n",
    "          the initial constant is not important.\n",
    "        \"\"\"\n",
    "\n",
    "        image_size, num_channels, num_labels = model.image_size, model.num_channels, model.num_labels\n",
    "        self.sess = sess\n",
    "        self.TARGETED = targeted\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.MAX_ITERATIONS = max_iterations\n",
    "        self.BINARY_SEARCH_STEPS = binary_search_steps\n",
    "        self.ABORT_EARLY = abort_early\n",
    "        self.CONFIDENCE = confidence\n",
    "        self.initial_const = initial_const\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.repeat = binary_search_steps >= 10\n",
    "\n",
    "        shape = (batch_size,image_size,image_size,num_channels)\n",
    "        \n",
    "        # the variable we're going to optimize over\n",
    "        modifier = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "        # these are variables to be more efficient in sending data to tf\n",
    "        self.timg = tf.Variable(np.zeros(shape), dtype=tf.float32)\n",
    "        self.tlab = tf.Variable(np.zeros((batch_size,num_labels)), dtype=tf.float32)\n",
    "        self.const = tf.Variable(np.zeros(batch_size), dtype=tf.float32)\n",
    "\n",
    "        # and here's what we use to assign them\n",
    "        self.assign_timg = tf.placeholder(tf.float32, shape)\n",
    "        self.assign_tlab = tf.placeholder(tf.float32, (batch_size,num_labels))\n",
    "        self.assign_const = tf.placeholder(tf.float32, [batch_size])\n",
    "        \n",
    "        # the resulting image, tanh'd to keep bounded from boxmin to boxmax\n",
    "        self.boxmul = (boxmax - boxmin) / 2.\n",
    "        self.boxplus = (boxmin + boxmax) / 2.\n",
    "#         self.newimg = tf.tanh(modifier + self.timg) * self.boxmul + self.boxplus\n",
    "        self.newimg = modifier + self.timg\n",
    "        \n",
    "        # Create the grid for bilinear interpolation\n",
    "        indices_grid = self._meshgrid(image_size, image_size)\n",
    "        print(\"meshgrid shape\", indices_grid.shape)\n",
    "        indices_grid = tf.tile(indices_grid, tf.stack([batch_size]))\n",
    "        print(\"batch_tile grid shape\", indices_grid.shape)\n",
    "        indices_grid = tf.reshape(indices_grid, (batch_size, 3, -1))\n",
    "        print(\"batch+3:\", indices_grid.shape)\n",
    "        transformed_grid = indices_grid\n",
    "        x_s = tf.slice(transformed_grid, [0, 0, 0], [-1, 1, -1])\n",
    "        print(\"grid x_s shape:\", x_s.shape)\n",
    "        y_s = tf.slice(transformed_grid, [0, 1, 0], [-1, 1, -1])\n",
    "\n",
    "        x_s_flatten = tf.reshape(x_s, [-1])\n",
    "        y_s_flatten = tf.reshape(y_s, [-1])\n",
    "        print(\"x_flatten_shape:\", x_s_flatten.shape)\n",
    "        \n",
    "        # bilinear interpolation\n",
    "        output_size = (image_size, image_size)\n",
    "        self.newimg = self._interpolate(self.newimg,\n",
    "                                 x_s_flatten,\n",
    "                                 y_s_flatten,\n",
    "                                 output_size)\n",
    "        self.newimg = tf.reshape(self.newimg, shape)\n",
    "        \n",
    "        self.newimg = tf.cast(self.newimg, dtype='float32')\n",
    "        print(self.newimg.shape)\n",
    "        \n",
    "        # prediction BEFORE-SOFTMAX of the model\n",
    "        self.output = model.predict(self.newimg)\n",
    "        \n",
    "        # distance to the input data\n",
    "#         self.stAdvdist = tf.reduce_sum(tf.square(self.newimg-(tf.tanh(self.timg) * self.boxmul + self.boxplus)),[1,2,3])\n",
    "        self.stdist = self.total_variation_based_loss(self.newimg)\n",
    "        self.stdist = tf.cast(self.stdist,  dtype='float32')\n",
    "    \n",
    "        # compute the probability of the label class versus the maximum other\n",
    "        real = tf.reduce_sum((self.tlab)*self.output,1)\n",
    "        other = tf.reduce_max((1-self.tlab)*self.output - (self.tlab*10000),1)\n",
    "\n",
    "        if self.TARGETED:\n",
    "            # if targetted, optimize for making the other class most likely\n",
    "            loss1 = tf.maximum(0.0, other-real+self.CONFIDENCE)\n",
    "        else:\n",
    "            # if untargeted, optimize for making this class least likely.\n",
    "            loss1 = tf.maximum(0.0, real-other+self.CONFIDENCE)\n",
    "\n",
    "        # sum up the losses\n",
    "        self.loss2 = tf.reduce_sum(self.const*self.stdist)\n",
    "        self.loss1 = tf.reduce_sum(loss1)\n",
    "        self.loss = self.loss1 + self.loss2\n",
    "        \n",
    "        # Setup the adam optimizer and keep track of variables we're creating\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        self.optimizer = optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss,\n",
    "                method='L-BFGS-B',  var_list = [modifier], var_to_bounds={modifier:([0,1])},\n",
    "                options={'maxiter': max_iterations}, \n",
    "                )\n",
    "#         optimizer = tf.train.AdamOptimizer(self.LEARNING_RATE)\n",
    "#         self.train = optimizer.minimize(self.loss, var_list=[modifier])\n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "\n",
    "        # these are the variables to initialize when we run\n",
    "        self.setup = []\n",
    "        self.setup.append(self.timg.assign(self.assign_timg))\n",
    "        self.setup.append(self.tlab.assign(self.assign_tlab))\n",
    "        self.setup.append(self.const.assign(self.assign_const))\n",
    "        \n",
    "        self.init = tf.variables_initializer(var_list=[modifier]+new_vars)\n",
    "    \n",
    "    def total_variation_based_loss(self, images):\n",
    "        \"\"\"\n",
    "          Calculate and return the total variation based loss for one or more images.\n",
    "          The total variation is the sum of the L2 norm for neighboring\n",
    "          pixel-values in the input images. This measures how much noise is in the\n",
    "          images.\n",
    "          This is based on the total variation of images in the tensorflow with the \n",
    "          following documention:\n",
    "          Total Variation:\n",
    "          This can be used as a loss-function during optimization so as to suppress\n",
    "          noise in images. If you have a batch of images, then you should calculate\n",
    "          the scalar loss-value as the sum:\n",
    "          `loss = tf.reduce_sum(tf.image.total_variation(images))`\n",
    "          This implements the anisotropic 2-D version of the formula described here:\n",
    "          https://en.wikipedia.org/wiki/Total_variation_denoising\n",
    "          Args:\n",
    "            images: 4-D Tensor of shape `[batch, height, width, channels]` or\n",
    "                    3-D Tensor of shape `[height, width, channels]`.\n",
    "            name: A name for the operation (optional).\n",
    "          Raises:\n",
    "            ValueError: if images.shape is not a 3-D or 4-D vector.\n",
    "          Returns:\n",
    "            The total variation of `images`.\n",
    "            If `images` was 4-D, return a 1-D float Tensor of shape `[batch]` with the\n",
    "            total variation for each image in the batch.\n",
    "            If `images` was 3-D, return a scalar float with the total variation for\n",
    "            that image.\n",
    "          \"\"\"\n",
    "        ndims = images.get_shape().ndims\n",
    "\n",
    "        if ndims == 3:\n",
    "            # The input is a single image with shape [height, width, channels].\n",
    "            # Calculate the difference of neighboring pixel-values.\n",
    "            # The images are shifted one pixel along the height and width by slicing.\n",
    "            pixel_dif1 = images[1:, :, :] - images[:-1, :, :]\n",
    "            pixel_dif2 = images[:, 1:, :] - images[:, :-1, :]\n",
    "            \n",
    "            # Sum for all axis. (None is an alias for all axis.)\n",
    "            sum_axis = None\n",
    "        elif ndims == 4:\n",
    "            # The input is a batch of images with shape:\n",
    "            # [batch, height, width, channels].\n",
    "            \n",
    "            # Calculate the difference of neighboring pixel-values.\n",
    "            # The images are shifted one pixel along the height and width by slicing.\n",
    "            pixel_dif1 = images[:, 1:, :, :] - images[:, :-1, :, :]\n",
    "            pixel_dif2 = images[:, :, 1:, :] - images[:, :, :-1, :]\n",
    "\n",
    "            # Only sum for the last 3 axis.\n",
    "            # This results in a 1-D tensor with the total variation for each image.\n",
    "            sum_axis = [1, 2, 3]\n",
    "        else:\n",
    "            raise ValueError('\\'images\\' must be either 3 or 4-dimensional.')\n",
    "\n",
    "        # Calculate the total variation by taking the absolute value of the\n",
    "        # pixel-differences and summing over the appropriate axis.\n",
    "        tot_var = (\n",
    "            tf.add(\n",
    "#                 tf.nn.l2_loss(pixel_dif1**2),\n",
    "#                 tf.nn.l2_loss(pixel_dif2**2)))\n",
    "            tf.reduce_sum(tf.square(pixel_dif1), axis=sum_axis) ,\n",
    "            tf.reduce_sum(tf.square(pixel_dif2), axis=sum_axis)\n",
    "            ))\n",
    "        return tot_var\n",
    "\n",
    "\n",
    "            # grid sampling, returns a tensor of size hxwx3\n",
    "    def _meshgrid(self, height, width):\n",
    "        x_linspace = tf.linspace(-1., 1., width)\n",
    "        y_linspace = tf.linspace(-1., 1., height)\n",
    "        x_coordinates, y_coordinates = tf.meshgrid(x_linspace, y_linspace)\n",
    "        x_coordinates = tf.reshape(x_coordinates, [-1])\n",
    "        y_coordinates = tf.reshape(y_coordinates, [-1])\n",
    "        ones = tf.ones_like(x_coordinates)\n",
    "        indices_grid = tf.concat([x_coordinates, y_coordinates, ones], 0)\n",
    "        return indices_grid\n",
    "\n",
    "    def _repeat(self, x, num_repeats):\n",
    "            ones = tf.ones((1, num_repeats), dtype='int32')\n",
    "            x = tf.reshape(x, shape=(-1,1))\n",
    "            x = tf.matmul(x, ones)\n",
    "            return tf.reshape(x, [-1])\n",
    "\n",
    "    # bilinear interpolation\n",
    "    def _interpolate(self, image, x, y, output_size):\n",
    "        batch_size = tf.shape(image)[0]\n",
    "        height = tf.shape(image)[1]\n",
    "        width = tf.shape(image)[2]\n",
    "        num_channels = tf.shape(image)[3]\n",
    "\n",
    "        x = tf.cast(x , dtype='float32')\n",
    "        y = tf.cast(y , dtype='float32')\n",
    "\n",
    "        height_float = tf.cast(height, dtype='float32')\n",
    "        width_float = tf.cast(width, dtype='float32')\n",
    "\n",
    "        output_height = output_size[0]\n",
    "        output_width  = output_size[1]\n",
    "        \n",
    "        # because the intial values are from -1 and 1, scale them to the original coordinates\n",
    "        x = .5*(x + 1.0)*(width_float)\n",
    "        y = .5*(y + 1.0)*(height_float)\n",
    "        \n",
    "        # Get the lower x coordinate\n",
    "        x0 = tf.cast(tf.floor(x), 'int32')\n",
    "        # upper x coordinate is just one plus the lower x\n",
    "        x1 = x0 + 1\n",
    "        y0 = tf.cast(tf.floor(y), 'int32')\n",
    "        y1 = y0 + 1\n",
    "        \n",
    "        # max y and max x for clipping the coordinates\n",
    "        max_y = tf.cast(height - 1, dtype='int32')\n",
    "        max_x = tf.cast(width - 1,  dtype='int32')\n",
    "        zero = tf.zeros([], dtype='int32')\n",
    "    \n",
    "        # Clip the coordinates\n",
    "        x0 = tf.clip_by_value(x0, zero, max_x)\n",
    "        x1 = tf.clip_by_value(x1, zero, max_x)\n",
    "        y0 = tf.clip_by_value(y0, zero, max_y)\n",
    "        y1 = tf.clip_by_value(y1, zero, max_y)\n",
    "        \n",
    "        # flatten the pixel values of input img\n",
    "        flat_image_dimensions = width*height\n",
    "        pixels_batch = tf.range(batch_size)*flat_image_dimensions\n",
    "        # flatten the output img dimensions\n",
    "        flat_output_dimensions = output_height*output_width\n",
    "        # get a array of ones for the output flattened dim\n",
    "        base = self._repeat(pixels_batch, flat_output_dimensions)\n",
    "        \n",
    "        print(\"base shape:\", base.shape)\n",
    "        base_y0 = base + y0*width\n",
    "        print(\"base_y0_shape\", base_y0.shape)\n",
    "        base_y1 = base + y1*width\n",
    "        indices_a = base_y0 + x0\n",
    "        print(\"indices_shape\", indices_a.shape)\n",
    "        indices_b = base_y1 + x0\n",
    "        indices_c = base_y0 + x1\n",
    "        indices_d = base_y1 + x1\n",
    "\n",
    "        flat_image = tf.reshape(image, shape=(-1, num_channels))\n",
    "        flat_image = tf.cast(flat_image, dtype='float32')\n",
    "        # get the pixel values corresponding to the indices from the image.\n",
    "        pixel_values_a = tf.gather(flat_image, indices_a)\n",
    "        pixel_values_b = tf.gather(flat_image, indices_b)\n",
    "        pixel_values_c = tf.gather(flat_image, indices_c)\n",
    "        pixel_values_d = tf.gather(flat_image, indices_d)\n",
    "        \n",
    "        # cast to float\n",
    "        x0 = tf.cast(x0, 'float32')\n",
    "        x1 = tf.cast(x1, 'float32')\n",
    "        y0 = tf.cast(y0, 'float32')\n",
    "        y1 = tf.cast(y1, 'float32')\n",
    "        \n",
    "        # Get the 4 areas calculated for the 4 coordinate points and the input point.\n",
    "        area_a = tf.expand_dims(((x1 - x) * (y1 - y)), 1)\n",
    "        area_b = tf.expand_dims(((x1 - x) * (y - y0)), 1)\n",
    "        area_c = tf.expand_dims(((x - x0) * (y1 - y)), 1)\n",
    "        area_d = tf.expand_dims(((x - x0) * (y - y0)), 1)\n",
    "        output = tf.add_n([area_a*pixel_values_a,\n",
    "                           area_b*pixel_values_b,\n",
    "                           area_c*pixel_values_c,\n",
    "                           area_d*pixel_values_d])\n",
    "        return output\n",
    "\n",
    "    def attack(self, imgs, targets):\n",
    "        \"\"\"\n",
    "        Perform the stAdv attack on the given images for the given targets.\n",
    "        If self.targeted is true, then the targets represents the target labels.\n",
    "        If self.targeted is false, then targets are the original class labels.\n",
    "        \"\"\"\n",
    "        r = []\n",
    "        print('go up to', len(imgs))\n",
    "        for i in range(0,len(imgs),self.batch_size):\n",
    "            print('attack for image', i)\n",
    "            r.extend(self.attack_batch(imgs[i:i+self.batch_size], targets[i:i+self.batch_size]))\n",
    "        return np.array(r)\n",
    "\n",
    "    def attack_batch(self, imgs, labs):\n",
    "        \"\"\"\n",
    "        Run the attack on a batch of images and labels.\n",
    "        \"\"\"\n",
    "        def compare(x,y):\n",
    "            if not isinstance(x, (float, int, np.int64)):\n",
    "                x = np.copy(x)\n",
    "                if self.TARGETED:\n",
    "                    x[y] -= self.CONFIDENCE\n",
    "                else:\n",
    "                    x[y] += self.CONFIDENCE\n",
    "                x = np.argmax(x)\n",
    "            if self.TARGETED:\n",
    "                return x == y\n",
    "            else:\n",
    "                return x != y\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        # convert to tanh-space\n",
    "#         imgs = np.arctanh((imgs - self.boxplus) / self.boxmul * 0.999999)\n",
    "\n",
    "        # set the lower and upper bounds accordingly\n",
    "        lower_bound = np.zeros(batch_size)\n",
    "        CONST = np.ones(batch_size)*self.initial_const\n",
    "        upper_bound = np.ones(batch_size)*1e10\n",
    "\n",
    "        # the best stAdv, score, and image attack\n",
    "        o_best_stAdv = [1e10]*batch_size\n",
    "        o_bestscore = [-1]*batch_size\n",
    "        # best image for the attack\n",
    "        o_bestattack = [np.zeros(imgs[0].shape)]*batch_size\n",
    "        \n",
    "        # binary seach for the correct c and also the best example.\n",
    "        for outer_step in range(self.BINARY_SEARCH_STEPS):\n",
    "            print(\"outer step:\", outer_step)\n",
    "            print(\"o_best_stAdv:\", o_best_stAdv)\n",
    "            \n",
    "            # completely reset adam's internal state.\n",
    "            self.sess.run(self.init)\n",
    "            batch = imgs[:batch_size]\n",
    "            batchlab = labs[:batch_size]\n",
    "    \n",
    "            beststAdv = [1e10]*batch_size\n",
    "            bestscore = [-1]*batch_size\n",
    "\n",
    "            # The last iteration (if we run many steps) repeat the search once.\n",
    "            if self.repeat == True and outer_step == self.BINARY_SEARCH_STEPS-1:\n",
    "                CONST = upper_bound\n",
    "\n",
    "            # set the variables so that we don't have to send them over again\n",
    "            self.sess.run(self.setup, {self.assign_timg: batch,\n",
    "                                       self.assign_tlab: batchlab,\n",
    "                                       self.assign_const: CONST})\n",
    "            \n",
    "            prev = 1e6\n",
    "            \n",
    "            for iteration in range(self.MAX_ITERATIONS):\n",
    "                # perform the attack \n",
    "                self.optimizer.minimize(self.sess)\n",
    "                l, stAdvs, scores, nimg = self.sess.run([\n",
    "#                                                        self.train,\n",
    "                                                         self.loss, \n",
    "                                                         self.stdist,\n",
    "                                                         self.output, \n",
    "                                                         self.newimg])\n",
    "\n",
    "                # print out the losses every 10%\n",
    "                if iteration%(self.MAX_ITERATIONS//10) == 0:\n",
    "                    print(\"iter:\", iteration, \"total_loss, L_adv, L_flow:\", self.sess.run((self.loss,self.loss1,self.loss2)))\n",
    "\n",
    "                # check if we should abort search if we're getting nowhere.\n",
    "                if self.ABORT_EARLY and iteration%(self.MAX_ITERATIONS//10) == 0:\n",
    "                    if l > prev*.9999:\n",
    "                        break\n",
    "                    prev = l\n",
    "\n",
    "                # adjust the best result found so far\n",
    "                for e,(stAdv,sc,ii) in enumerate(zip(stAdvs,scores,nimg)):\n",
    "                    if stAdv < beststAdv[e] and compare(sc, np.argmax(batchlab[e])):\n",
    "                        beststAdv[e] = stAdv\n",
    "                        bestscore[e] = np.argmax(sc)\n",
    "                    if stAdv < o_best_stAdv[e] and compare(sc, np.argmax(batchlab[e])):\n",
    "                        o_best_stAdv[e] = stAdv\n",
    "                        o_bestscore[e] = np.argmax(sc)\n",
    "                        o_bestattack[e] = ii\n",
    "\n",
    "            # adjust the constant as needed through binary search\n",
    "            for e in range(batch_size):\n",
    "                if compare(bestscore[e], np.argmax(batchlab[e])) and bestscore[e] != -1:\n",
    "                    # success, divide const by two\n",
    "                    upper_bound[e] = min(upper_bound[e],CONST[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        CONST[e] = (lower_bound[e] + upper_bound[e])/2\n",
    "                else:\n",
    "                    # failure, either multiply by 10 if no solution found yet\n",
    "                    #          or do binary search with the known upper bound\n",
    "                    lower_bound[e] = max(lower_bound[e],CONST[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        CONST[e] = (lower_bound[e] + upper_bound[e])/2\n",
    "                    else:\n",
    "                        CONST[e] *= 10\n",
    "\n",
    "        # return the best solution found\n",
    "        o_best_stAdv = np.array(o_best_stAdv)\n",
    "        return o_bestattack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run STAdv attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test_attack.py -- sample code to test attack procedure\n",
    "##\n",
    "## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show(img):\n",
    "    \"\"\"\n",
    "    Show MNSIT digits in the console.\n",
    "    \"\"\"\n",
    "    remap = \"  .*#\"+\"#\"*100\n",
    "    img = (img.flatten()+.5)*3\n",
    "    if len(img) != 784: return\n",
    "    print(\"START\")\n",
    "    for i in range(28):\n",
    "        print(\"\".join([remap[int(round(x))] for x in img[i*28:i*28+28]]))\n",
    "\n",
    "def plot(img, image_size, title):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(img.reshape(image_size, image_size), cmap='gray', interpolation='none')\n",
    "    plt.title(title, fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def generate_data(data, samples, targeted=True, start=0, inception=False):\n",
    "    \"\"\"\n",
    "    Generate the input data to the attack algorithm.\n",
    "    data: the images to attack\n",
    "    samples: number of samples to use\n",
    "    targeted: if true, construct targeted attacks, otherwise untargeted attacks\n",
    "    start: offset into data to use\n",
    "    inception: if targeted and inception, randomly sample 100 targets intead of 1000\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(samples):\n",
    "        if targeted:\n",
    "            if inception:\n",
    "                seq = random.sample(range(1,1001), 10)\n",
    "            else:\n",
    "                seq = range(data.test_labels.shape[1])\n",
    "\n",
    "            for j in seq:\n",
    "                if (j == np.argmax(data.test_labels[start+i])) and (inception == False):\n",
    "                    continue\n",
    "                inputs.append(data.test_data[start+i])\n",
    "                targets.append(np.eye(data.test_labels.shape[1])[j])\n",
    "        else:\n",
    "            inputs.append(data.test_data[start+i])\n",
    "            targets.append(data.test_labels[start+i])\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('meshgrid shape', TensorShape([Dimension(2352)]))\n",
      "('batch_tile grid shape', TensorShape([Dimension(21168)]))\n",
      "('batch+3:', TensorShape([Dimension(9), Dimension(3), Dimension(784)]))\n",
      "('grid x_s shape:', TensorShape([Dimension(9), Dimension(1), Dimension(784)]))\n",
      "('x_flatten_shape:', TensorShape([Dimension(7056)]))\n",
      "('base shape:', TensorShape([Dimension(None)]))\n",
      "('base_y0_shape', TensorShape([Dimension(7056)]))\n",
      "('indices_shape', TensorShape([Dimension(7056)]))\n",
      "(9, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('go up to', 9)\n",
      "('attack for image', 0)\n",
      "('outer step:', 0)\n",
      "('o_best_stAdv:', [10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0])\n",
      "('iter:', 0, 'total_loss, L_adv, L_flow:', (0.41764188, 0.0, 0.41764188))\n",
      "('iter:', 100, 'total_loss, L_adv, L_flow:', (0.41764188, 0.0, 0.41764188))\n",
      "('outer step:', 1)\n",
      "('o_best_stAdv:', [50.980164, 45.072746, 41.029385, 44.30838, 47.03125, 47.19017, 51.946083, 46.465485, 43.618187])\n",
      "('iter:', 0, 'total_loss, L_adv, L_flow:', (0.21036308, 2.3841858e-07, 0.21036284))\n",
      "('iter:', 100, 'total_loss, L_adv, L_flow:', (0.21034886, 0.0, 0.21034886))\n",
      "('outer step:', 2)\n",
      "('o_best_stAdv:', [50.78866, 45.072746, 41.029385, 44.30838, 47.03125, 47.19017, 51.911278, 46.465485, 43.618187])\n",
      "('iter:', 0, 'total_loss, L_adv, L_flow:', (0.11183404, 0.0, 0.11183404))\n",
      "('iter:', 100, 'total_loss, L_adv, L_flow:', (0.11183404, 0.0, 0.11183404))\n",
      "('outer step:', 3)\n",
      "('o_best_stAdv:', [50.78866, 45.072746, 41.029385, 44.30838, 47.03125, 47.19017, 51.911278, 46.465485, 43.618187])\n",
      "('iter:', 0, 'total_loss, L_adv, L_flow:', (0.071394, 0.0, 0.071394))\n",
      "('iter:', 100, 'total_loss, L_adv, L_flow:', (0.071394, 0.0, 0.071394))\n",
      "('outer step:', 4)\n",
      "('o_best_stAdv:', [50.78866, 45.072746, 41.029385, 44.30838, 47.03125, 47.19017, 51.911278, 46.465485, 43.618187])\n",
      "('iter:', 0, 'total_loss, L_adv, L_flow:', (0.0466117, 0.0, 0.0466117))\n",
      "('iter:', 100, 'total_loss, L_adv, L_flow:', (0.0466117, 0.0, 0.0466117))\n",
      "('outer step:', 5)\n",
      "('o_best_stAdv:', [50.78866, 45.072746, 41.029385, 44.30838, 47.03125, 47.19017, 51.911278, 46.465485, 43.618187])\n",
      "('iter:', 0, 'total_loss, L_adv, L_flow:', (0.029489674, 0.0, 0.029489674))\n",
      "('iter:', 100, 'total_loss, L_adv, L_flow:', (0.029489674, 0.0, 0.029489674))\n",
      "('outer step:', 6)\n",
      "('o_best_stAdv:', [50.78866, 45.072746, 41.029385, 44.30838, 47.03125, 47.19017, 51.911278, 46.465485, 43.618187])\n",
      "('iter:', 0, 'total_loss, L_adv, L_flow:', (0.021677235, 0.0, 0.021677235))\n",
      "('iter:', 100, 'total_loss, L_adv, L_flow:', (0.021677235, 0.0, 0.021677235))\n",
      "('outer step:', 7)\n",
      "('o_best_stAdv:', [50.78866, 45.072746, 41.029385, 44.30838, 47.03125, 47.19017, 51.911278, 46.465485, 43.618187])\n",
      "('iter:', 0, 'total_loss, L_adv, L_flow:', (0.01810017, 0.0, 0.01810017))\n",
      "('iter:', 100, 'total_loss, L_adv, L_flow:', (0.01810017, 0.0, 0.01810017))\n",
      "('outer step:', 8)\n",
      "('o_best_stAdv:', [50.78866, 45.072746, 41.029385, 44.30838, 47.03125, 47.19017, 51.911278, 46.465485, 43.618187])\n",
      "('iter:', 0, 'total_loss, L_adv, L_flow:', (0.014286004, 0.0, 0.014286004))\n",
      "('iter:', 100, 'total_loss, L_adv, L_flow:', (0.014286004, 0.0, 0.014286004))\n",
      "('Took', 244.42609310150146, 'seconds to run', 9, 'samples.')\n",
      "Valid:\n",
      "START\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "       ...                  \n",
      "      ******.........       \n",
      "          .**********.      \n",
      "                   **       \n",
      "                   *.       \n",
      "                  **        \n",
      "                 .**        \n",
      "                 **         \n",
      "                .*.         \n",
      "                .*          \n",
      "                *.          \n",
      "               **           \n",
      "              **.           \n",
      "             .**            \n",
      "             **             \n",
      "            **              \n",
      "           .**              \n",
      "           ***              \n",
      "           ***              \n",
      "           *.               \n",
      "                            \n",
      "Adversarial:\n",
      "START\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "       ...                 .\n",
      "         ..                .\n",
      "         ..*.   .*.        .\n",
      "      ......   ..*.        .\n",
      "      ...***..*****.       .\n",
      "         .....******.      .\n",
      "         ..   .*..**.      .\n",
      "     .   ...  .. .*..      .\n",
      "     ..          .*.       .\n",
      "     *..        .**.       .\n",
      "     ..         **.        .\n",
      "     .         .#*         .\n",
      "     .         *#.         .\n",
      "     ...      .**          .\n",
      "      ..      **.          .\n",
      "             *##.          .\n",
      "            *##..          .\n",
      "           .#*.            .\n",
      "       ....*#.             .\n",
      "        **###.             .\n",
      "          ***.             .\n",
      "          .*.              .\n",
      "                           .\n",
      "............................\n",
      "('Classification:', array([[ 4.4580417 ,  0.3263261 ,  1.4311533 , -3.3992512 , -2.1799703 ,\n",
      "        -0.28826252, -1.1109141 ,  2.2500067 , -0.86806   , -2.143006  ]],\n",
      "      dtype=float32))\n",
      "('classification:', 0)\n",
      "('Total distortion:', 8.422688913737563)\n",
      "Valid:\n",
      "START\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "       ...                  \n",
      "      ******.........       \n",
      "          .**********.      \n",
      "                   **       \n",
      "                   *.       \n",
      "                  **        \n",
      "                 .**        \n",
      "                 **         \n",
      "                .*.         \n",
      "                .*          \n",
      "                *.          \n",
      "               **           \n",
      "              **.           \n",
      "             .**            \n",
      "             **             \n",
      "            **              \n",
      "           .**              \n",
      "           ***              \n",
      "           ***              \n",
      "           *.               \n",
      "                            \n",
      "Adversarial:\n",
      "START\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                  .        .\n",
      "          ...   ..**       .\n",
      "      .....     ...*.      .\n",
      "      ...***.*******.      .\n",
      "         ..****.****.      .\n",
      "         ..*... ..**.      .\n",
      "          .      .**       .\n",
      "                 .**       .\n",
      "                .**.       .\n",
      "                **.        .\n",
      "               .**         .\n",
      "               .*.         .\n",
      "              .**           \n",
      "             .**.   .      .\n",
      "           .*###.          .\n",
      "            *#***...       .\n",
      "           .**   ..        .\n",
      "       ....**.             .\n",
      "        .*##*.             .\n",
      "          *#*.             .\n",
      "          .#*              .\n",
      "                           .\n",
      "............................\n",
      "('Classification:', array([[-4.52923  , 14.850547 , 11.771359 , -1.7385179, -2.1284266,\n",
      "        -3.8711758, -2.8703942,  9.661618 , -7.395518 , -9.679629 ]],\n",
      "      dtype=float32))\n",
      "('classification:', 1)\n",
      "('Total distortion:', 7.769601951035784)\n",
      "Valid:\n",
      "START\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "       ...                  \n",
      "      ******.........       \n",
      "          .**********.      \n",
      "                   **       \n",
      "                   *.       \n",
      "                  **        \n",
      "                 .**        \n",
      "                 **         \n",
      "                .*.         \n",
      "                .*          \n",
      "                *.          \n",
      "               **           \n",
      "              **.           \n",
      "             .**            \n",
      "             **             \n",
      "            **              \n",
      "           .**              \n",
      "           ***              \n",
      "           ***              \n",
      "           *.               \n",
      "                            \n",
      "Adversarial:\n",
      "START\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "         .**.   ..*.       .\n",
      "      ....**.    ..*.      .\n",
      "      **.***********.      .\n",
      "      ..  ...*******.      .\n",
      "             .***..*.      .\n",
      "                  **       .\n",
      "                 .*.       .\n",
      "                .**.       .\n",
      "                **.        .\n",
      "               .*.         .\n",
      "               .*          .\n",
      "              .**           \n",
      "            ..**.          .\n",
      "           .*###*          .\n",
      "           .*#***.         .\n",
      "         ...**             .\n",
      "        ..***.             .\n",
      "         .*#*.             .\n",
      "          .**.             .\n",
      "          .#*              .\n",
      "                           .\n",
      "............................\n",
      "('Classification:', array([[-1.1994268,  2.8041697, 12.915372 ,  2.13383  , -3.0982246,\n",
      "        -5.3073473, -6.3451276,  8.977933 , -2.348702 , -5.4668193]],\n",
      "      dtype=float32))\n",
      "('classification:', 2)\n",
      "('Total distortion:', 7.768789095791736)\n",
      "Valid:\n",
      "START\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "       ...                  \n",
      "      ******.........       \n",
      "          .**********.      \n",
      "                   **       \n",
      "                   *.       \n",
      "                  **        \n",
      "                 .**        \n",
      "                 **         \n",
      "                .*.         \n",
      "                .*          \n",
      "                *.          \n",
      "               **           \n",
      "              **.           \n",
      "             .**            \n",
      "             **             \n",
      "            **              \n",
      "           .**              \n",
      "           ***              \n",
      "           ***              \n",
      "           *.               \n",
      "                            \n",
      "Adversarial:\n",
      "START\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "        .                  .\n",
      "                           .\n",
      "         .**.   ..**       .\n",
      "      .......    .**.      .\n",
      "      **.***..***..*.      .\n",
      "     ...  ....***.**.      .\n",
      "              .**..*.      .\n",
      "               .  **.      .\n",
      "                 .**.      .\n",
      "                .**.       .\n",
      "                .*         .\n",
      "                *.         .\n",
      "               .*          .\n",
      "           ....*.           \n",
      "           *****           .\n",
      "            .**.           .\n",
      "            .**.           .\n",
      "            **              \n",
      "        ...*#*              \n",
      "        **###.             .\n",
      "          *#*.             .\n",
      "          .#*              .\n",
      "                           .\n",
      "............................\n",
      "('Classification:', array([[-8.1017418e+00, -2.4063230e+00, -2.9362280e+00,  1.8517330e+01,\n",
      "        -5.7699399e+00,  4.9767208e+00, -1.1555010e+01,  7.1817698e+00,\n",
      "        -3.4641922e-03, -8.3476067e-01]], dtype=float32))\n",
      "('classification:', 3)\n",
      "('Total distortion:', 7.482206472444413)\n",
      "Valid:\n",
      "START\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "       ...                  \n",
      "      ******.........       \n",
      "          .**********.      \n",
      "                   **       \n",
      "                   *.       \n",
      "                  **        \n",
      "                 .**        \n",
      "                 **         \n",
      "                .*.         \n",
      "                .*          \n",
      "                *.          \n",
      "               **           \n",
      "              **.           \n",
      "             .**            \n",
      "             **             \n",
      "            **              \n",
      "           .**              \n",
      "           ***              \n",
      "           ***              \n",
      "           *.               \n",
      "                            \n",
      "Adversarial:\n",
      "START\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "         ..                .\n",
      "         .*..   ..*.       .\n",
      "      ......   ...*.       .\n",
      "      .*.***.******.       .\n",
      "        ..**********.      .\n",
      "        ..*******.**.      .\n",
      "          ...... .**.      .\n",
      "                 .*#.      .\n",
      "                .*#*.      .\n",
      "     .          *#*.       .\n",
      "     .         .**.        .\n",
      "               *#.         .\n",
      "              .#*.         .\n",
      "             .**.  ..      .\n",
      "            .##.           .\n",
      "            *#*            .\n",
      "       .   .#*             .\n",
      "       ....**.             .\n",
      "        .*##*.             .\n",
      "          *#*.             .\n",
      "          .#*              .\n",
      "                           .\n",
      "............................\n",
      "('Classification:', array([[-2.298206  ,  1.0152961 ,  1.7176764 , -0.71084034,  2.451213  ,\n",
      "        -2.230588  , -2.430797  ,  2.4470859 , -0.28292066, -0.44250435]],\n",
      "      dtype=float32))\n",
      "('classification:', 4)\n",
      "('Total distortion:', 8.121530584391289)\n",
      "Valid:\n",
      "START\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "       ...                  \n",
      "      ******.........       \n",
      "          .**********.      \n",
      "                   **       \n",
      "                   *.       \n",
      "                  **        \n",
      "                 .**        \n",
      "                 **         \n",
      "                .*.         \n",
      "                .*          \n",
      "                *.          \n",
      "               **           \n",
      "              **.           \n",
      "             .**            \n",
      "             **             \n",
      "            **              \n",
      "           .**              \n",
      "           ***              \n",
      "           ***              \n",
      "           *.               \n",
      "                            \n",
      "Adversarial:\n",
      "START\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "       ..                  .\n",
      "         ...               .\n",
      "          **.     ..       .\n",
      "      ....**      ...      .\n",
      "      .*.***..*****..      .\n",
      "         .**..*##***.      .\n",
      "         ... .***.**...    .\n",
      "          ..  ....*....    .\n",
      "                 .*.       .\n",
      "     .          .*.        .\n",
      "     .          .*         .\n",
      "                *.         .\n",
      "               .*          .\n",
      "      ...     .*.          .\n",
      "       .      **.          .\n",
      "             *#*           .\n",
      "            *##.           .\n",
      "            ##.            .\n",
      "        ...*#*             .\n",
      "        **###.             .\n",
      "          *#*.             .\n",
      "          .#.              .\n",
      "                           .\n",
      "............................\n",
      "('Classification:', array([[-3.784914 , -3.07249  , -5.768868 ,  1.6456523, -1.8303945,\n",
      "        10.553513 , -6.8150373,  5.6118727, -1.8917522,  4.7174087]],\n",
      "      dtype=float32))\n",
      "('classification:', 5)\n",
      "('Total distortion:', 7.912433844556453)\n",
      "Valid:\n",
      "START\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "       ...                  \n",
      "      ******.........       \n",
      "          .**********.      \n",
      "                   **       \n",
      "                   *.       \n",
      "                  **        \n",
      "                 .**        \n",
      "                 **         \n",
      "                .*.         \n",
      "                .*          \n",
      "                *.          \n",
      "               **           \n",
      "              **.           \n",
      "             .**            \n",
      "             **             \n",
      "            **              \n",
      "           .**              \n",
      "           ***              \n",
      "           ***              \n",
      "           *.               \n",
      "                            \n",
      "Adversarial:\n",
      "START\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "       ...                 .\n",
      "         ...               .\n",
      "          ...   ...        .\n",
      "      ......  .......      .\n",
      "      ...***..*****.       .\n",
      "         ..*..**#***.      .\n",
      "         ...  .*****.      .\n",
      "     .    ..  ....*..      .\n",
      "     .           .**.      .\n",
      "     ..         .***.      .\n",
      "    ...         **..       .\n",
      "    ..         .#*         .\n",
      "     ..        *#.         .\n",
      "     ...      .**          .\n",
      "      ..   ...**.          .\n",
      "            *###.           \n",
      "            *##*.          .\n",
      "           .#*.            .\n",
      "       ....*#.             .\n",
      "        **###.             .\n",
      "          *#*.              \n",
      "          .#*              .\n",
      "           ..              .\n",
      "............................\n",
      "('Classification:', array([[ 0.07225116,  0.39619654,  0.1694109 , -0.8020975 , -0.15209095,\n",
      "         0.05768644,  0.58350426,  0.58350414, -0.28168127, -0.87152654]],\n",
      "      dtype=float32))\n",
      "('classification:', 6)\n",
      "('Total distortion:', 8.553755478623756)\n",
      "Valid:\n",
      "START\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "       ...                  \n",
      "      ******.........       \n",
      "          .**********.      \n",
      "                   **       \n",
      "                   *.       \n",
      "                  **        \n",
      "                 .**        \n",
      "                 **         \n",
      "                .*.         \n",
      "                .*          \n",
      "                *.          \n",
      "               **           \n",
      "              **.           \n",
      "             .**            \n",
      "             **             \n",
      "            **              \n",
      "           .**              \n",
      "           ***              \n",
      "           ***              \n",
      "           *.               \n",
      "                            \n",
      "Adversarial:\n",
      "START\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "       ..                  .\n",
      "          .                .\n",
      "         .**.   .**.       .\n",
      "      ....**     .*.       .\n",
      "      *******.*****.       .\n",
      "      .  .....******.      .\n",
      "          .  .***.**.      .\n",
      "          ..  .. .***.     .\n",
      "                 .**.      .\n",
      "     ..         .***       .\n",
      "     ..         **.        .\n",
      "               .*.         .\n",
      "     .         **          .\n",
      "     ....     .*.          .\n",
      "      ...    .**.          .\n",
      "             *#*.          .\n",
      "            .#*.           .\n",
      "        .   **.            .\n",
      "        .. .*.             .\n",
      "        .*###.             .\n",
      "          *##.             .\n",
      "          .**              .\n",
      "                           .\n",
      "............................\n",
      "('Classification:', array([[-2.0721655, -3.1488202, -1.1030343,  2.533398 , -1.3868307,\n",
      "        -0.0758482, -5.346894 ,  2.2321594,  5.34275  ,  0.8729384]],\n",
      "      dtype=float32))\n",
      "('classification:', 8)\n",
      "('Total distortion:', 8.080410248567597)\n",
      "Valid:\n",
      "START\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "       ...                  \n",
      "      ******.........       \n",
      "          .**********.      \n",
      "                   **       \n",
      "                   *.       \n",
      "                  **        \n",
      "                 .**        \n",
      "                 **         \n",
      "                .*.         \n",
      "                .*          \n",
      "                *.          \n",
      "               **           \n",
      "              **.           \n",
      "             .**            \n",
      "             **             \n",
      "            **              \n",
      "           .**              \n",
      "           ***              \n",
      "           ***              \n",
      "           *.               \n",
      "                            \n",
      "Adversarial:\n",
      "START\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "                           .\n",
      "          .                .\n",
      "         .**.   ..         .\n",
      "      ......     .         .\n",
      "      .*.***..*****.       .\n",
      "      .  ....***#***.      .\n",
      "             .***..*.      .\n",
      "              .*..***.     .\n",
      "              ....***      .\n",
      "                .***.      .\n",
      "                *#*.       .\n",
      "               .#*         .\n",
      "               *#.         .\n",
      "              .#*          .\n",
      "              **            \n",
      "             .*.           .\n",
      "            .#*            .\n",
      "            **             .\n",
      "        ...*#.             .\n",
      "        **###.             .\n",
      "          *#*.             .\n",
      "          .*.              .\n",
      "                           .\n",
      "............................\n",
      "('Classification:', array([[ -3.1351736 ,  -5.5112534 ,  -2.9571204 ,   2.561234  ,\n",
      "         -0.79233694,  -1.3486615 , -10.975728  ,   7.5655603 ,\n",
      "          0.55114913,  10.427538  ]], dtype=float32))\n",
      "('classification:', 9)\n",
      "('Total distortion:', 7.5928715955270905)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    data, model =  MNIST(), MNISTModel(\"models/mnist\", sess)\n",
    "    attack = STAdv(sess, model, batch_size=9, max_iterations=1000, confidence=0)\n",
    "\n",
    "    inputs, targets = generate_data(data, samples=1, targeted=True,\n",
    "                                    start=0, inception=False)\n",
    "    timestart = time.time()\n",
    "    adv = attack.attack(inputs, targets)\n",
    "    timeend = time.time()\n",
    "\n",
    "    print(\"Took\",timeend-timestart,\"seconds to run\",len(inputs),\"samples.\")\n",
    "    \n",
    "    image_size = 28\n",
    "    for i in range(len(adv)):\n",
    "        print(\"Valid:\")\n",
    "        show(inputs[i])\n",
    "#         plot(inputs[i], image_size, \"valid\")\n",
    "        print(\"Adversarial:\")\n",
    "        show(adv[i])\n",
    "#         plot(inputs[i],image_size, \"adv\")\n",
    "        prediction = model.model.predict(adv[i:i+1])\n",
    "        print(\"Classification:\", prediction)\n",
    "\n",
    "        print(\"classification:\", np.argmax(prediction))\n",
    "        \n",
    "        print(\"Total distortion:\", np.sum((adv[i]-inputs[i])**2)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
