{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to generate a baseline on the MNIST cluttered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import keras.backend as K\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "DIM = 60\n",
    "mnist_cluttered = \"./../datasets/mnist_cluttered_60x60_6distortions.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from spatial_transformer import SpatialTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train sample:', array([ 0.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32))\n",
      "Train samples: (50000, 60, 60, 1)\n",
      "Validation samples: (10000, 60, 60, 1)\n",
      "Test samples: (10000, 60, 60, 1)\n",
      "('sample output:', array([[ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]]))\n",
      "('output shape:', (50000, 10))\n",
      "('Input shape:', (60, 60, 1))\n"
     ]
    }
   ],
   "source": [
    "data = np.load(mnist_cluttered)\n",
    "X_train, y_train = data['x_train'], np.argmax(data['y_train'], axis=-1)\n",
    "print(\"X_train sample:\", X_train[0])\n",
    "X_valid, y_valid = data['x_valid'], np.argmax(data['y_valid'], axis=-1)\n",
    "X_test, y_test = data['x_test'], np.argmax(data['y_test'], axis=-1)\n",
    "# reshape for convolutions\n",
    "X_train = X_train.reshape((X_train.shape[0], DIM, DIM, 1))\n",
    "X_valid = X_valid.reshape((X_valid.shape[0], DIM, DIM, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], DIM, DIM, 1))\n",
    "#one hot\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(\"Train samples: {}\".format(X_train.shape))\n",
    "print(\"Validation samples: {}\".format(X_valid.shape))\n",
    "print(\"Test samples: {}\".format(X_test.shape))\n",
    "print(\"sample output:\",y_train)\n",
    "print(\"output shape:\", y_train.shape)\n",
    "input_shape =  np.squeeze(X_train.shape[1:])\n",
    "input_shape = (60,60,1)\n",
    "print(\"Input shape:\",input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAG2CAYAAADfkJmbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFbxJREFUeJzt3X20XWV94PHfb0gCSpyYzgIN1gAdoKWxWl9QOjNALFQQ\ni5TSamlx6lvRVRaU2FJwOgWmFamUqlMd6WALioMzWugsGXnpcllABloLBfsC2C5tk8ambbBBZQI1\nQJ75Y5/Uy3Xvk3tu7r353eTzWSsr8Ozz7P3kEu43+5znnGRrLQCggn+1uxcAADuIEgBliBIAZYgS\nAGWIEgBliBIAZYgS8yozD87M7Zl59e5eS3WZeXtmbt/d64DdSZSYWGZ+d2Z+IDP/PDO/lpnfzMy/\ny8xPZ+abM3PZPF13fWb+9Zjj2zPzD+bj2gukjX7MyI6IjX68cczjLp7yuKunHfvpKcd+bWD+caPj\n1w7M/bY/cGTmqsx8X2Y+kJlbM/OxzNwwWvO7MvPQ0eOumXL9mfxYzP99mYElu3sBLC6ZeVFEXBQR\nGRF/GBGfjYj/FxHPiYi1EfHhiHh7RLx8Hi7vnd5PtyNiT0bEWyPiI9MfkJkZEW+KiCdi/P/vLSLO\nzcz/1lrbuCuLysw1EfG5iHh2RPz5aF1bIuLA6H5fvDMi/joi/iYi/vfo56nWRsRxEXFHRNw+7dj6\nXVkb9YkSM5aZ/ykiLomIDRHx4621e3sec3JE/PwCL21v9+mI+JHMPLK19tC0YydFxOqI+L2I+NEx\n5/hSRBwWEe+OiDfs4nr+a3RBuri19q7pBzPzkIhYFhHRWrsxIm6cdjyjC9PtrbVf2cW1sMh4+o4Z\nycyDI+LiiNgWESf3BSkiorV2c3TfCHd2vsHXT6Y8LfQfR/9+3OixqyPikGlP51y94/HR/Wl/7bTj\nF0079ysy8/rM/PvR045/m5m/lZmrBtb4VGYuzcyLMvOLmfnPPU+BnZGZt2XmI5n5eGY+mJm/NPQ0\nZmb+RGb+yegprX/MzGv7rj+B347uzvVneo79TERsjYjrxsxvEfHJiPhCRJyRmS/ZhbVERPzA6Off\n7L1Ya+tba3+1i9dgD+VOiZl6c0QsjYiP9/xp/Glaa0/M4Hw7e/1k6rH10d2hrRuNvy+6b8IR3TfS\nHccvGf3zR6bMvX3HP2TmmyPiv0fEP0f3p/ONEXF4RLwlIk7JzFe01r7Ss4YbIuJlEXFLdE83bZ5y\nzqsj4o2jc10fEV+LiKMj4lcj4gcz84daa9unPH5dRPxGRDwyWufXI+LEiLh79M+z8ZfRPV12ZmZe\nsOPrn5nPiYgfjoiPRcQ3xszP0a/15yPiDyLiioj4wVmuJSLinyLieRFxRET0/uEFhogSM/Xvo/vG\nteAvNLfWNkTEr2Tmm7p/bb/a87A/y8xLImJ931M+mXl4RFwZ3WsZx7XW/mHKsVdGxGeie9rp9OlT\no7tDW9Nae2TaOd8YXZBuiIifaq1tm3LsoujuLM+OiA+Mxg6OiF+L7vWVF0957eadmXl9dE+vzfZ1\nsw9HF58fjYhPjMbeFBH7RHcn9cydnaC1dntm3hQRJ2fmD7fWPj3LtXwiusD9n8y8MiJui4gvtNYe\nneX52It4+o6Z2vH00lfGPqqun43uD2HnTQ1SRERr7bbo7pxOycz9p81rEfGfpwdp5Oei20DwlqlB\nGnlXdPH5qSljZ47W8Js9mwnOj4hd2Q5+fXR3X1OfwntLRDzUWvvDCc7zi6N1vCczZ/v94Zci4qqI\n+I7ownxHRHwtMx8a7cg7dJbnZS/gTom9xdGjn9dmZt/OwAOju6s4IiLun3bsnukPzsxnRMQLI+Lh\niFjXvTb/9IdExDcj4sgpYy8e/fy56Q9urf1NZm6M7q5sYq21b2bm/4iIszPzuyLi0Ij4txFx3oTn\neSgzfye6uJ0VEb81i7Vsi4i3Z+YvR/f64isi4iXRPQX6cxFxVmb++Oj1R3gaUWKm/j4ivie61woW\no38z+vkXxjymRcTybxts7R97HrsyuvAcEN0W+XHn3GHF6Oe+80VE/EPMMkojH46Ic6LbHn5odK+d\nfWwW57koIn4yIi7OzNnMj4iI1trDo+t/LCIiM58dEe+JLnhXZ+Z3ttaenO352TN5+o6Z+r/RfRM+\nfo7Otz0iYuApomfP0TWm2rGJ4F+31vYZ+LGktXbnhOe7f8z59mmtLemZ85yBcz530l/UVK21v4iI\nP4ruabvTIuKGgacdd3aezRHx69Gt88JdWdO0834tuvew/W10MX/BXJ2bPYcoMVPXRPf6yemZ+T3j\nHji0FXqaHd8sn99z7KiBOU9F9xTbkO1jjv/R6Odjd760nWutbY2IByJizegOYCbuiy7sx00/MHqd\npe9rMakPR/cNf2l0Gxxm64qI2BTdjsfvnIN1RUS3SyW6LeoR39pBCf9ClJiR0Q64SyJi34i4OTNf\n2ve4zDwpuq3TO/PH0fPemsw8PiJ+YmDOP0XEAZm575jjQ9/YPxjdJx+8b7QTb/q6l2bmf5jBuqd6\nb3Rfj2syc8X0g5n57Mx88ZSh66IL+zmjnXg7HpfRRWAu/n/8XxHxIxFxamvtjtmepLX2eET8cnS7\n9i6OyT7+6KKpv75px34suqeBt0TEX4xbwsxXy57Ea0rMWGvtsszcJ7pvUvdk5t3RvQ9lx8cMHRvd\n+37+eAanuya6HWfvzMzvj4gHo9tkcFJ0nz7wYz1zPhvdi+W/n5mfi24jwZ9O2br82Yh4fWbeGN1d\nyRMR8bnW2p2ttb8cvU/pdyLigcy8NSL+Kro7itURcUx07z/63gm+HteM3mj6sxHx5cz8/eiemvqO\n6F7TOTYirh4dj9bahsy8MLoA3Z+Zn4hvvU9pRUT8WUR830yvP7Cmx2PaJyTsgo9Et1Fi0jWti4hL\nMvP+6H5/PBzdr+8l0b2x9omIePtO3s/mLmovJUpMpLX2rsz83ei+0b4yuvfp7BfdXcoXIuKy+PZP\nD/i2N8q21h7OzGOje+3imOi+gd8bESdEt2ts+vuFIrpt1isi4pSI+HfRPVX30eg+Ziei29m1PbrX\nvV4d3Z3Hf4mIO0fXvC4zvxDde2heGRE/FN1TSZsi4nfjW+/vmb72cV+PczLzluheKzk+utfDtkQX\np/dM/1q01t6XmZuiC/JPR8SjEXFrRFwQEf9zZ9ebdH09j+17fO94a61l5vnxrTvfmc59TXRf/+Oi\nC+5zortL/Up0W8U/0Fp7YJZrZQ+X3VO8ALD7eU0JgDJECYAyRAmAMuZ9o0Nm/sl8XwOAxaO11vuW\nkogF2OiQmXZSAPAvWmuDW/49fQdAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRA\nGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZ\nogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIEQBmi\nBEAZogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIEQBmiBEAZogRAGaIE\nQBmiBEAZogRAGaIEQBmiBEAZS3b3AmAuHX300YPHjj322N7xyy+/fL6WA0zInRIAZYgSAGWIEgBl\niBIAZYgSAGVka21+L5A5vxfYQ+2///694xdffPHgnE996lO943fdddecrKmS0047rXf80ksvHZxz\n2GGH9Y4vW7ZsTtYEzExrLYeOuVMCoAxRAqAMUQKgDFECoAxRAqAMUQKgDFvCi7rssst6x88///zB\nOZ/5zGd6x1/96lfPyZoW2oEHHjh4bNWqVXN2nS1btgwe27hx45xdB+jYEg7AoiBKAJQhSgCUIUoA\nlCFKAJThr0PfjQ466KDBY29961t7xx977LHBOVddddXEaxjaxbZ8+fLBOYcccsjE1zn44IMHj51+\n+ukTzzniiCN6x2ezm3TTpk2Dx84999ze8aEPvwV2jTslAMoQJQDKECUAyhAlAMoQJQDKECUAyvCB\nrLvRu9/97sFjQx+8mjn4OYaD28W/9KUvDc5ZuXJl7/h+++03OOeAAw7oHZ/v30tTffzjH594DevX\nr+8dv/766wfnDJ3vgQceGF4cMJYPZAVgURAlAMoQJQDKECUAyhAlAMqw+24BrF27tnf8lltuGZyz\nZEn/Z+W+973vHZzzspe9rHd83Aeorl69evDYkMcff7x3/Morr5z4XBERDz30UO/4zTffPDhn8+bN\ns7oWsPvZfQfAoiBKAJQhSgCUIUoAlCFKAJQhSgCU0b/vmDl1/PHH944vXbp0cM6pp57aO37TTTfN\nyZoAKnKnBEAZogRAGaIEQBmiBEAZogRAGXbfLYCjjjqqd3zch+Hec88987UcgLLcKQFQhigBUIYo\nAVCGKAFQhigBUIYoAVCGLeFFjdsuDrCncqcEQBmiBEAZogRAGaIEQBmiBEAZdt8VtWbNmt7x22+/\nfUGuv99++w0eu+yyy3rH161bN1/LAfYS7pQAKEOUAChDlAAoQ5QAKEOUAChDlAAoI+f7gz8zc6//\nZNHTTjutd/yTn/zk4JzHHnusd3zr1q2Dc4b+W477b3zttdf2jl944YUTX2efffYZnAOwQ2sth465\nUwKgDFECoAxRAqAMUQKgDFECoAy773ajF7zgBYPHTjrppN7xd7zjHRNfZ//99x889qxnPat3PHNw\nc8zg7runnnpqcM6GDRsGj91www294/fee+/gnJtuuql3fGjXIlCH3XcALAqiBEAZogRAGaIEQBmi\nBEAZogRAGbaE70H23Xff3vHLL798cM6555478XWGfs9cd911g3PWrFkzeOywww7rHX/GM54xOOe+\n++7rHV+3bt3gnLvvvnvwGLBwbAkHYFEQJQDKECUAyhAlAMoQJQDKWLK7F8Dced3rXtc7fvbZZw/O\n2b59e+/4uF2Z3/jGN3rH3/CGNwzOGfcBr0cffXTv+Ac/+MHBOS996Ut7x9euXTs4x+47qM+dEgBl\niBIAZYgSAGWIEgBliBIAZYgSAGX4QNaili9f3js+7sNVX/va1/aOr1q1auLrj/t9sW3btt7xZz7z\nmRNfZ5wDDzxw8NimTZt6x7du3To451WvelXv+Oc///nJFgbsEh/ICsCiIEoAlCFKAJQhSgCUIUoA\nlOEDWXejJUuGv/yXXnpp7/hZZ501X8t5mnEfoLp06dIFWcPq1asnnjNu991Xv/rVXVkOsADcKQFQ\nhigBUIYoAVCGKAFQhigBUIYoAVCGLeG70Uc/+tHBY69//et7x8dt1V4oQ2tYsWLF4Jwzzzxz8NiJ\nJ57YO37yyScPztm8eXPv+AknnDA458tf/vLgsYVw3nnnDR57//vfv4ArgbrcKQFQhigBUIYoAVCG\nKAFQhigBUIa/Dn1CBxxwQO/4ww8/vMArmblxO/ZWrlzZO/785z9/cM7QX3s+bjfhoYceOnjskUce\n6R3fuHHj4Jwbb7yxd/zBBx8cnHPFFVf0js/3/wM7PO95zxs8tlAfcgsV+OvQAVgURAmAMkQJgDJE\nCYAyRAmAMkQJgDJsCZ/Qtdde2zs+tFV8nHHbl2+99dbe8WOOOWZwzlFHHTXxGlatWtU7vmbNmsE5\nQ1vMx/1euu+++waPXXDBBb3jd9xxx+Ccbdu2DR4bMpt1z6VxW/OXLPHZyOw9bAkHYFEQJQDKECUA\nyhAlAMoQJQDKsPtuQuecc07v+Li/hnvcX+s9qXE7uBZqF9lVV13VO37llVcOztmwYcPgsUcffXTi\nNTz55JMTz6nM7jv2JnbfAbAoiBIAZYgSAGWIEgBliBIAZYgSAGXYEj5Hli5dOnhs5cqVc3adClvC\nN2/evCDXGceWcFi8bAkHYFEQJQDKECUAyhAlAMoQJQDKsOVnjjzxxBODxyrsVtvTzOVutXE7Gu+6\n667e8Ze//OUTX+f++++feA7sbdwpAVCGKAFQhigBUIYoAVCGKAFQhigBUIYt4ez1XvOa1wwee9GL\nXjTx+YY+GPeEE06Y+Fywt3GnBEAZogRAGaIEQBmiBEAZogRAGaIEQBm2hLPXO/LIIwePLVu2rHd8\naNt3RMT69et7x7/+9a9PtC7YG7lTAqAMUQKgDFECoAxRAqAMUQKgjBy3i2hOLpA5vxcAYFFpreXQ\nMXdKAJQhSgCUIUoAlCFKAJQhSgCUIUoAlCFKAJQhSgCUIUoAlCFKAJQhSgCUIUoAlCFKAJQhSgCU\nIUoAlCFKAJQhSgCUIUoAlCFKAJSxZHcvYE+xYsWKwWNLlvR/mQ8//PDBOWeeeWbv+HOf+9zBOaee\nemrv+NKlSwfnAFTiTgmAMkQJgDJECYAyRAmAMkQJgDKytTa/F8ic3wvsZZYtWzZ47IUvfGHv+L33\n3jtfywGYWGsth465UwKgDFECoAxRAqAMUQKgDFECoAxRAqAMW8IBWFC2hAOwKIgSAGWIEgBliBIA\nZYgSAGX469D3IMccc0zv+J133rnAKwGYHXdKAJQhSgCUIUoAlCFKAJQhSgCUIUoAlGFL+CJzxhln\nDB770Ic+1Du+cuXK+VoOwJxypwRAGaIEQBmiBEAZogRAGaIEQBl23/U48cQT5/R8mf1/8+/b3va2\nwTkHHXRQ7/gRRxwxOGf58uWTLQygGHdKAJQhSgCUIUoAlCFKAJQhSgCUIUoAlJGttfm9QOb8XmAe\nPPnkk7t7CXNqyRI7/4E6Wmv975MJd0oAFCJKAJQhSgCUIUoAlCFKAJRhW1aPoQ9QHWfcLsYtW7b0\njn/xi1+c+Hy33Xbb4JxTTjll8BjAYuBOCYAyRAmAMkQJgDJECYAyRAmAMkQJgDJ8ICsAC8oHsgKw\nKIgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBl\niBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWI\nEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgS\nAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIA\nZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBl\niBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWI\nEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgSAGWIEgBliBIAZYgS\nAGWIEgBlLFmAa9y3ANcAYA+QrbXdvQYAiAhP3wFQiCgBUIYoAVCGKAFQhigBUIYoAVCGKAFQhigB\nUIYoAVCGKAFQhigBUIYoAVCGKAFQhigBUIYoAVCGKAFQhigBUIYoAVCGKAFQhigBUMb/B84agNr2\nztSyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabec12b5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(X_train[101].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "plt.title('Cluttered MNIST', fontsize=20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# # model.add(SpatialTransformer(localization_net=locnet,\n",
    "# #                              output_size=(30,30), input_shape=input_shape))\n",
    "# model.add(Convolution2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(32, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Convolution2D(32, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Convolution2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(nb_classes))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History \n",
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(64, (9, 9), padding='same', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (1, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\n",
    "\n",
    "model.add(Convolution2D(64, (7, 7), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (1, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\n",
    "model.add(Dropout(rate=0.4))\n",
    "\n",
    "model.add(Convolution2D(64, (5, 5), padding='same', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (1, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\n",
    "model.add(Dropout(rate=0.4))\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (1, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 60, 60, 64)        5248      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 60, 60, 64)        4160      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 30, 64)        200768    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 30, 30, 64)        4160      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 15, 15, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 15, 15, 64)        4160      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 7, 7, 64)          4160      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 437,194\n",
      "Trainable params: 437,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "29100/50000 [================>.............] - ETA: 43s - loss: 0.2376 - acc: 0.9281"
     ]
    }
   ],
   "source": [
    "nb_epochs = 40 # you probably want to go longer than this\n",
    "batch_size = 100\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=nb_epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[history],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history['acc'])\n",
    "plt.plot(history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
