{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments by rotating the filters of the convolution layer: 90/45 degrees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug flag to test if the implementation is correct\n",
    "debug = 1\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kriti/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "permutation = [[1, 0], [0, 0], [0, 1], [2, 0], [1, 1], [0, 2], [2, 1], [2, 2], [1, 2]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train sample:', (3600,))\n",
      "Train samples: (50000, 60, 60, 1)\n",
      "Validation samples: (10000, 60, 60, 1)\n",
      "Test samples: (10000, 60, 60, 1)\n",
      "('output shape:', (50000, 10))\n",
      "('Input shape:', (60, 60, 1))\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "\n",
    "DIM = 60\n",
    "mnist_cluttered = \"datasets/mnist_cluttered_60x60_6distortions.npz\"\n",
    "\n",
    "# Preparing data\n",
    "data = np.load(mnist_cluttered)\n",
    "X_train, y_train = data['x_train'], np.argmax(data['y_train'], axis=-1)\n",
    "print(\"X_train sample:\", X_train[0].shape)\n",
    "X_valid, y_valid = data['x_valid'], np.argmax(data['y_valid'], axis=-1)\n",
    "X_test, y_test = data['x_test'], np.argmax(data['y_test'], axis=-1)\n",
    "# reshape for convolutions\n",
    "X_train = X_train.reshape((X_train.shape[0], DIM, DIM, 1))\n",
    "X_valid = X_valid.reshape((X_valid.shape[0], DIM, DIM, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], DIM, DIM, 1))\n",
    "#one hot\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(\"Train samples: {}\".format(X_train.shape))\n",
    "print(\"Validation samples: {}\".format(X_valid.shape))\n",
    "print(\"Test samples: {}\".format(X_test.shape))\n",
    "\n",
    "print(\"output shape:\", y_train.shape)\n",
    "input_shape =  np.squeeze(X_train.shape[1:])\n",
    "input_shape = (DIM, DIM, 1)\n",
    "print(\"Input shape:\",input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7586a4a510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(X_train[101].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "plt.title('Cluttered MNIST', fontsize=20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras import layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the rotation function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shift_rotate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-63dba85b2cbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_rotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shift_rotate' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" Sanity check shift_rotate implementation\n",
    "\"\"\"\n",
    "\n",
    "if(debug):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "\n",
    "    w = np.array(\n",
    "        [\n",
    "            [\n",
    "                [\n",
    "                    [1, 2, 3],\n",
    "                    [4, 5, 6],\n",
    "                    [7, 8, 9]\n",
    "                ],\n",
    "                [\n",
    "                    [11, 22, 33],\n",
    "                    [44, 55, 66],\n",
    "                    [77, 88, 99]\n",
    "                ],\n",
    "                [\n",
    "                    [111, 222, 333],\n",
    "                    [444, 555, 666],\n",
    "                    [777, 888, 999]\n",
    "                ]\n",
    "            ],\n",
    "            [\n",
    "                [\n",
    "                    [1, 2, 3],\n",
    "                    [4, 5, 6],\n",
    "                    [7, 8, 9]\n",
    "                ],\n",
    "                [\n",
    "                    [11, 22, 33],\n",
    "                    [44, 55, 66],\n",
    "                    [77, 88, 99]\n",
    "                ],\n",
    "                [\n",
    "                    [111, 222, 333],\n",
    "                    [444, 555, 666],\n",
    "                    [777, 888, 999]\n",
    "                ]\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    w = np.moveaxis(w, (2, 3), (0, 1))\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    # shape: (row, col, inp_nb, out_nb) -> (3, 3, 2, 3)\n",
    "    w = tf.constant(w)\n",
    "\n",
    "    w1 = shift_rotate(w, 4)\n",
    "    print w1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(convs):\n",
    "    if convs is None:\n",
    "        convs = [conv_old, conv_old, conv_old, conv_old]\n",
    "    model = Sequential()\n",
    "\n",
    "    # model.add(SpatialTransformer(localization_net=locnet,\n",
    "    #                              output_size=(30,30), input_shape=input_shape))\n",
    "    model.add(convs[0](32, (3, 3), padding='same', input_shape=input_shape, use_bias=False, activation='relu'))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(convs[0](32, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(convs[0](32, (3, 3), padding='same', use_bias=False, activation='relu'))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(convs[1](32, (3, 3), use_bias=False, activation='relu'))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to rotate the filters and new convolution layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift times according to the parameter shift\n",
    "def shift_rotate(w, shift=1):\n",
    "    shape = w.get_shape()\n",
    "    for i in range(shift):\n",
    "        #tf.gather_nd gathers the values according to the indices specified in permutation.\n",
    "        w = tf.reshape(tf.gather_nd(w, permutation), shape)\n",
    "    return w\n",
    "\n",
    "#new convolution class which does convolution using 4 rotations\n",
    "class Convolution2D_4(Conv2D):\n",
    "    def call(self, x, mask=None):\n",
    "        w = self.weights[0]\n",
    "        w_rot = [w]\n",
    "        # shifts of 90 degrees everytime\n",
    "        for i in range(3):\n",
    "            w = shift_rotate(w, shift=2)\n",
    "            w_rot.append(w)\n",
    "        \n",
    "        # convolves all the 4 filters on the input image.\n",
    "        outputs = tf.stack([K.conv2d(x, w_i, strides=self.strides,\n",
    "                                     padding=self.padding,\n",
    "                                     data_format=self.data_format,\n",
    "#                                      filters=self.weights[0].get_shape\n",
    "                                    ) for w_i in w_rot])\n",
    "\n",
    "        output = K.max(outputs, 0)\n",
    "\n",
    "        if self.use_bias:\n",
    "            if self.data_format == 'channels_first':\n",
    "                output += K.reshape(self.use_bias, (1, self.filters, 1, 1))\n",
    "            elif self.data_format == 'channels_last':\n",
    "                output += K.reshape(self.use_bias, (1, 1, 1, self.filters))\n",
    "            else:\n",
    "                raise ValueError('Invalid dim_ordering:', self.data_format)\n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Convolution2D_8(Conv2D):\n",
    "    def call(self, x, mask=None):\n",
    "        w = self.weights[0]\n",
    "        \n",
    "        w_rot = [w]\n",
    "        for i in range(7):\n",
    "            w = shift_rotate(w)\n",
    "            w_rot.append(w)\n",
    "\n",
    "        outputs = tf.stack([K.conv2d(x, w_i, strides = self.strides,\n",
    "                                     padding=self.padding,\n",
    "                                     data_format=self.data_format,\n",
    "#                                      filters=self.weights[0].get_shape\n",
    "                                    ) for w_i in w_rot])\n",
    "#         set_trace()\n",
    "        output = K.max(outputs, 0)\n",
    "        \n",
    "        if self.use_bias:\n",
    "            if self.data_format == 'channels_first':\n",
    "                output += K.reshape(self.use_bias, (1, self.filters, 1, 1))\n",
    "            elif self.data_format == 'channels_last':\n",
    "                output += K.reshape(self.use_bias, (1, 1, 1, self.filters))\n",
    "            else:\n",
    "                raise ValueError('Invalid dim_ordering:', self.data_format)\n",
    "        \n",
    "\n",
    "        output = self.activation(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name, model, nb_epochs, X_train, y_train, X_valid, y_valid):\n",
    "    maxVAcc = maxTAcc = maxVScore = maxTScore = epoch = 0\n",
    "    for e in range(nb_epochs):\n",
    "        print('-'*40)\n",
    "#         progbar = generic_utils.Progbar(X_train.shape[0])\n",
    "        for b in range(150):\n",
    "            print(b)\n",
    "            f = b * batch_size\n",
    "            l = (b+1) * batch_size\n",
    "            X_batch = X_train[f:l].astype('float32')\n",
    "            y_batch = y_train[f:l].astype('float32')\n",
    "            loss = model.train_on_batch(X_batch, y_batch)\n",
    "            print(loss)\n",
    "#             progbar.add(X_batch.shape[0], values=[(\"train loss\", loss)])\n",
    "        scorev, accv = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "        scoret, acct = model.evaluate(X_test, y_test, verbose=1)\n",
    "        if(maxTAcc > acct):\n",
    "            maxTAcc = acct\n",
    "            maxVacc = accv\n",
    "            maxVScore = scorev\n",
    "            maxTScore = scoret\n",
    "            epoch = e\n",
    "        if(e%1==0):\n",
    "            print('Epoch: {0} | Valid Score: {1}| Test Score: {2}| Valid Acc: {3} | Test Acc: {4}'.format(e, scorev, scoret, accv, acct))\n",
    "    return maxVAcc, maxTAcc, maxVScore, maxTScore, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_rot_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "convolution2d_4_1 (Convoluti (None, 60, 60, 32)        288       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "convolution2d_4_2 (Convoluti (None, 30, 30, 32)        9216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "convolution2d_4_3 (Convoluti (None, 15, 15, 32)        9216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 5, 5, 32)          9216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 63,530\n",
      "Trainable params: 63,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-7ca67e4978ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmaxVAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxTAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxVScore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxTScore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results for:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-7464cd6abbb7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(run_name, model, nb_epochs, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#             print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#             progbar.add(X_batch.shape[0], values=[(\"train loss\", loss)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kriti/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m   1066\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/kriti/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kriti/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kriti/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kriti/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kriti/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kriti/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kriti/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv_8 = Convolution2D_8\n",
    "conv_old = Conv2D\n",
    "conv_4 = Convolution2D_4\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Cleanup old weight dir.\n",
    "    import os, shutil\n",
    "    shutil.rmtree('weights', ignore_errors=True)\n",
    "    os.makedirs('weights')\n",
    "\n",
    "    names = ['8_rot_4', '8_rot_3', '8_rot_2', '8_rot_1', '4_rot_4', '4_rot_3', '4_rot_2', '4_rot_1', 'baseline']\n",
    "    convs = [\n",
    "        [conv_4, conv_old, conv_old, conv_4], \n",
    "        [conv_8, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_old, conv_8],\n",
    "        [conv_4, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_old, conv_4], \n",
    "        None\n",
    "        \n",
    "    ]\n",
    "\n",
    "nb_epochs = 110 # you probably want to go longer than this\n",
    "batch_size = 256\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(names[i])\n",
    "    model = get_model(convs[i])\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    maxVAcc, maxTAcc, maxVScore, maxTScore, epoch = train(names[i], model, nb_epochs, X_train, y_train, X_valid, y_valid)\n",
    "    f = open('results.txt','a') \n",
    "    f.write(\"Results for:\", names[i])\n",
    "    f.write('\\n')\n",
    "    f.write('maxVAcc: {0}, maxTAcc: {1}, maxVScore: {2}, maxTScore: {3}, epoch: {4}'.format( maxVAcc, maxTAcc, maxVScore, maxTScore, epoch ))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.close()\n",
    "    print('maxVAcc: {0}, maxTAcc: {1}, maxVScore: {2}, maxTScore: {3}, epoch: {4}'.format( maxVAcc, maxTAcc, maxVScore, maxTScore, epoch ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named train",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-254013cf063c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcifar10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named train"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from keras.layers import Convolution2D as conv_old\n",
    "\n",
    "\n",
    "def get_probs_matched(imgs, model, idx):\n",
    "    probs = model.predict_proba(imgs, verbose=0)\n",
    "    preds = probs.argmax(axis=-1)\n",
    "    probs = probs[:, y_test[idx][0]]\n",
    "    matched = (len(np.where(preds == y_test[idx][0])[0]) * 100.0) / len(imgs)\n",
    "    return probs, matched\n",
    "\n",
    "\n",
    "def compare(test_id, angles, models):\n",
    "    img = X_test[test_id]\n",
    "    imgs = np.array([ndimage.rotate(img, rot, reshape=False) for rot in angles])\n",
    "\n",
    "    all_probs = []\n",
    "    all_matched = []\n",
    "    for model in models:\n",
    "        probs, matched = get_probs_matched(imgs, model, test_id)\n",
    "        all_probs.append(probs)\n",
    "        all_matched.append(matched)\n",
    "\n",
    "    return all_probs, all_matched\n",
    "\n",
    "\n",
    "def plot_multi(names, models, angles, runs=1000):\n",
    "    indices = np.random.permutation(len(X_test))[:runs]\n",
    "\n",
    "    matched_all = []\n",
    "    for i, idx in enumerate(indices):\n",
    "        print(\"Processing {}/{}\".format(i, len(indices)))\n",
    "        probs, matched = compare(idx, angles, models)\n",
    "        matched_all.append(matched)\n",
    "\n",
    "    matched_all = np.array(matched_all)\n",
    "    order = np.argsort(np.mean(matched_all, axis=0))\n",
    "    df = pd.DataFrame.from_items([(names[i], matched_all[:, i]) for i in order])\n",
    "    sb.boxplot(data=df)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_single(names, models, angles, test_id):\n",
    "    all_probs, all_matched = compare(test_id, angles, models)\n",
    "    legends = []\n",
    "\n",
    "    order = np.argsort(all_matched)\n",
    "    for i in order:\n",
    "        plt.plot(angles, all_probs[i])\n",
    "        legends.append('{} {:.2f}%'.format(names[i], all_matched[i]))\n",
    "\n",
    "    plt.ylabel('Prediction probability of correct class')\n",
    "    plt.legend(legends, loc=9, bbox_to_anchor=(0.5, -0.05), ncol=len(names))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    names = ['baseline', '8_rot_4', '8_rot_3', '8_rot_2', '8_rot_1', '4_rot_4', '4_rot_3', '4_rot_2', '4_rot_1']\n",
    "    convs = [\n",
    "        None,\n",
    "        [conv_8, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_old, conv_8],\n",
    "        [conv_4, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_old, conv_4],\n",
    "    ]\n",
    "\n",
    "    models = []\n",
    "    indices = range(len(names))\n",
    "    for i in indices:\n",
    "        model = get_model(convs[i])\n",
    "        model.load_weights('./weights/{}.hdf5'.format(names[i]))\n",
    "        models.append(model)\n",
    "\n",
    "    angles = np.arange(0, 360, 1)\n",
    "    # plot_single([names[i] for i in indices], models, angles=angles, test_id=5)\n",
    "    plot_multi(names, models, angles=angles, runs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
