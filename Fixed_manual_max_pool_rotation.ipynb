{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments by rotating the filters of the convolution layer: 90/45 degrees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# debug flag to test if the implementation is correct\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "permutation = [[1, 0], [0, 0], [0, 1], [2, 0], [1, 1], [0, 2], [2, 1], [2, 2], [1, 2]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the rotation function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  9  99 999]\n",
      "   [  9  99 999]]\n",
      "\n",
      "  [[  8  88 888]\n",
      "   [  8  88 888]]\n",
      "\n",
      "  [[  7  77 777]\n",
      "   [  7  77 777]]]\n",
      "\n",
      "\n",
      " [[[  6  66 666]\n",
      "   [  6  66 666]]\n",
      "\n",
      "  [[  5  55 555]\n",
      "   [  5  55 555]]\n",
      "\n",
      "  [[  4  44 444]\n",
      "   [  4  44 444]]]\n",
      "\n",
      "\n",
      " [[[  3  33 333]\n",
      "   [  3  33 333]]\n",
      "\n",
      "  [[  2  22 222]\n",
      "   [  2  22 222]]\n",
      "\n",
      "  [[  1  11 111]\n",
      "   [  1  11 111]]]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Sanity check shift_rotate implementation\n",
    "\"\"\"\n",
    "\n",
    "if(debug):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "\n",
    "    w = np.array(\n",
    "        [\n",
    "            [\n",
    "                [\n",
    "                    [1, 2, 3],\n",
    "                    [4, 5, 6],\n",
    "                    [7, 8, 9]\n",
    "                ],\n",
    "                [\n",
    "                    [11, 22, 33],\n",
    "                    [44, 55, 66],\n",
    "                    [77, 88, 99]\n",
    "                ],\n",
    "                [\n",
    "                    [111, 222, 333],\n",
    "                    [444, 555, 666],\n",
    "                    [777, 888, 999]\n",
    "                ]\n",
    "            ],\n",
    "            [\n",
    "                [\n",
    "                    [1, 2, 3],\n",
    "                    [4, 5, 6],\n",
    "                    [7, 8, 9]\n",
    "                ],\n",
    "                [\n",
    "                    [11, 22, 33],\n",
    "                    [44, 55, 66],\n",
    "                    [77, 88, 99]\n",
    "                ],\n",
    "                [\n",
    "                    [111, 222, 333],\n",
    "                    [444, 555, 666],\n",
    "                    [777, 888, 999]\n",
    "                ]\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    w = np.moveaxis(w, (2, 3), (0, 1))\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    # shape: (row, col, inp_nb, out_nb) -> (3, 3, 2, 3)\n",
    "    w = tf.constant(w)\n",
    "\n",
    "    w1 = shift_rotate(w, 4)\n",
    "    print w1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train sample:', (3600,))\n",
      "Train samples: (50000, 60, 60, 1)\n",
      "Validation samples: (10000, 60, 60, 1)\n",
      "Test samples: (10000, 60, 60, 1)\n",
      "('output shape:', (50000, 10))\n",
      "('Input shape:', (60, 60, 1))\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "\n",
    "DIM = 60\n",
    "mnist_cluttered = \"datasets/mnist_cluttered_60x60_6distortions.npz\"\n",
    "\n",
    "# Preparing data\n",
    "data = np.load(mnist_cluttered)\n",
    "X_train, y_train = data['x_train'], np.argmax(data['y_train'], axis=-1)\n",
    "print(\"X_train sample:\", X_train[0].shape)\n",
    "X_valid, y_valid = data['x_valid'], np.argmax(data['y_valid'], axis=-1)\n",
    "X_test, y_test = data['x_test'], np.argmax(data['y_test'], axis=-1)\n",
    "# reshape for convolutions\n",
    "X_train = X_train.reshape((X_train.shape[0], DIM, DIM, 1))\n",
    "X_valid = X_valid.reshape((X_valid.shape[0], DIM, DIM, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], DIM, DIM, 1))\n",
    "#one hot\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(\"Train samples: {}\".format(X_train.shape))\n",
    "print(\"Validation samples: {}\".format(X_valid.shape))\n",
    "print(\"Test samples: {}\".format(X_test.shape))\n",
    "\n",
    "print(\"output shape:\", y_train.shape)\n",
    "input_shape =  np.squeeze(X_train.shape[1:])\n",
    "input_shape = (DIM, DIM, 1)\n",
    "print(\"Input shape:\",input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAG2CAYAAADfkJmbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nztSyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7bd8647550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(X_train[101].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "plt.title('Cluttered MNIST', fontsize=20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras import layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to rotate the filters and new convolution layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shift times according to the parameter shift\n",
    "def shift_rotate(w, shift=1):\n",
    "    shape = w.get_shape()\n",
    "    for i in range(shift):\n",
    "        #tf.gather_nd gathers the values according to the indices specified in permutation.\n",
    "        w = tf.reshape(tf.gather_nd(w, permutation), shape)\n",
    "    return w\n",
    "\n",
    "#new convolution class which does convolution using 4 rotations\n",
    "class Convolution2D_4(Convolution2D):\n",
    "    def call(self, x, mask=None):\n",
    "        w = tf.convert_to_tensor(self.get_weights()[0])\n",
    "        w_rot = [w]\n",
    "        # shifts of 90 degrees everytime\n",
    "        for i in range(3):\n",
    "            w = shift_rotate(w, shift=2)\n",
    "            w_rot.append(w)\n",
    "        \n",
    "        # convolves all the 4 filters on the input image.\n",
    "        outputs = tf.stack([K.conv2d(x, w_i, strides=self.subsample,\n",
    "                                     border_mode=self.border_mode,\n",
    "                                     dim_ordering=self.dim_ordering,\n",
    "                                     filter_shape=self.W_shape)])# for w_i in w_rot])\n",
    "\n",
    "        output = K.max(outputs, 0)\n",
    "\n",
    "        if self.bias:\n",
    "            if self.dim_ordering == 'th':\n",
    "                output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n",
    "            elif self.dim_ordering == 'tf':\n",
    "                output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n",
    "            else:\n",
    "                raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Convolution2D_8(Convolution2D):\n",
    "    def call(self, x, mask=None):\n",
    "        w = tf.convert_to_tensor(self.get_weights()[0])\n",
    "        w_rot = [w]\n",
    "        for i in range(7):\n",
    "            w = shift_rotate(w)\n",
    "            w_rot.append(w)\n",
    "\n",
    "        outputs = tf.stack([K.conv2d(x, w_i, strides=self.subsample,\n",
    "                                     border_mode=self.border_mode,\n",
    "                                     dim_ordering=self.dim_ordering,\n",
    "                                     filter_shape=self.W_shape) ])#for w_i in w_rot])\n",
    "\n",
    "        output = K.max(outputs, 0)\n",
    "\n",
    "        if self.bias:\n",
    "            if self.dim_ordering == 'th':\n",
    "                output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n",
    "            elif self.dim_ordering == 'tf':\n",
    "                output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n",
    "            else:\n",
    "                raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n",
    "        output = self.activation(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(convs):\n",
    "    if convs is None:\n",
    "        convs = [conv_old, conv_old, conv_old, ]\n",
    "    model = Sequential()\n",
    "\n",
    "    # model.add(SpatialTransformer(localization_net=locnet,\n",
    "    #                              output_size=(30,30), input_shape=input_shape))\n",
    "    model.add(convs[0](32, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(convs[0](32, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(convs[0](32, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(convs[1](32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(run_name, model, nb_epochs, X_train, y_train, X_valid, y_valid):\n",
    "    maxVAcc = maxTAcc = maxVScore = maxTScore = epoch = 0\n",
    "    for e in range(nb_epochs):\n",
    "#         print('-'*40)\n",
    "#         progbar = generic_utils.Progbar(X_train.shape[0])\n",
    "        for b in range(150):\n",
    "            #print(b)\n",
    "            f = b * batch_size\n",
    "            l = (b+1) * batch_size\n",
    "            X_batch = X_train[f:l].astype('float32')\n",
    "            y_batch = y_train[f:l].astype('float32')\n",
    "            loss = model.train_on_batch(X_batch, y_batch)\n",
    "#             print(loss)\n",
    "#             progbar.add(X_batch.shape[0], values=[(\"train loss\", loss)])\n",
    "        scorev, accv = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "        scoret, acct = model.evaluate(X_test, y_test, verbose=1)\n",
    "        if(maxTAcc > acct):\n",
    "            maxTAcc = acct\n",
    "            maxVacc = accv\n",
    "            maxVScore = scorev\n",
    "            maxTScore = scoret\n",
    "            epoch = e\n",
    "        if(e%1==0):\n",
    "            print('Epoch: {0} | Valid Score: {1}| Test Score: {2}| Valid Acc: {3} | Test Acc: {4}'.format(e, scorev, scoret, accv, acct))\n",
    "    return maxVAcc, maxTAcc, maxVScore, maxTScore, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_rot_4\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Convolution2D_8' object has no attribute 'subsample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-cad6f82ce82d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mmaxVAcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxTAcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxVScore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxTScore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-076ed2e49d92>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(convs)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# model.add(SpatialTransformer(localization_net=locnet,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#                              output_size=(30,30), input_shape=input_shape))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    465\u001b[0m                 \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m                 \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m                 \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-135-e0425eb54485>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     47\u001b[0m                                      \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mborder_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                                      \u001b[0mdim_ordering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                                      filter_shape=self.W_shape) for w_i in w_rot])\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Convolution2D_8' object has no attribute 'subsample'"
     ]
    }
   ],
   "source": [
    "conv_8 = Convolution2D_8\n",
    "conv_old = Convolution2D\n",
    "conv_4 = Convolution2D_4\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Cleanup old weight dir.\n",
    "    import os, shutil\n",
    "    shutil.rmtree('weights', ignore_errors=True)\n",
    "    os.makedirs('weights')\n",
    "\n",
    "    names = ['8_rot_4', '8_rot_3', '8_rot_2', '8_rot_1', '4_rot_4', '4_rot_3', '4_rot_2', '4_rot_1', 'baseline']\n",
    "    convs = [\n",
    "        [conv_8, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_old, conv_8],\n",
    "        [conv_4, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_old, conv_4],\n",
    "        None\n",
    "    ]\n",
    "\n",
    "nb_epochs = 110 # you probably want to go longer than this\n",
    "batch_size = 256\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(names[i])\n",
    "    model = get_model(convs[i])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    maxVAcc, maxTAcc, maxVScore, maxTScore, epoch = train(names[i], model, nb_epochs, X_train, y_train, X_valid, y_valid)\n",
    "    f = open('results.txt','a') \n",
    "    f.write(\"Results for:\", names[i])\n",
    "    f.write('\\n')\n",
    "    f.write('maxVAcc: {0}, maxTAcc: {1}, maxVScore: {2}, maxTScore: {3}, epoch: {4}'.format( maxVAcc, maxTAcc, maxVScore, maxTScore, epoch ))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.close()\n",
    "    print('maxVAcc: {0}, maxTAcc: {1}, maxVScore: {2}, maxTScore: {3}, epoch: {4}'.format( maxVAcc, maxTAcc, maxVScore, maxTScore, epoch ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named train",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-254013cf063c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcifar10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named train"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from keras.layers import Convolution2D as conv_old\n",
    "\n",
    "\n",
    "def get_probs_matched(imgs, model, idx):\n",
    "    probs = model.predict_proba(imgs, verbose=0)\n",
    "    preds = probs.argmax(axis=-1)\n",
    "    probs = probs[:, y_test[idx][0]]\n",
    "    matched = (len(np.where(preds == y_test[idx][0])[0]) * 100.0) / len(imgs)\n",
    "    return probs, matched\n",
    "\n",
    "\n",
    "def compare(test_id, angles, models):\n",
    "    img = X_test[test_id]\n",
    "    imgs = np.array([ndimage.rotate(img, rot, reshape=False) for rot in angles])\n",
    "\n",
    "    all_probs = []\n",
    "    all_matched = []\n",
    "    for model in models:\n",
    "        probs, matched = get_probs_matched(imgs, model, test_id)\n",
    "        all_probs.append(probs)\n",
    "        all_matched.append(matched)\n",
    "\n",
    "    return all_probs, all_matched\n",
    "\n",
    "\n",
    "def plot_multi(names, models, angles, runs=1000):\n",
    "    indices = np.random.permutation(len(X_test))[:runs]\n",
    "\n",
    "    matched_all = []\n",
    "    for i, idx in enumerate(indices):\n",
    "        print(\"Processing {}/{}\".format(i, len(indices)))\n",
    "        probs, matched = compare(idx, angles, models)\n",
    "        matched_all.append(matched)\n",
    "\n",
    "    matched_all = np.array(matched_all)\n",
    "    order = np.argsort(np.mean(matched_all, axis=0))\n",
    "    df = pd.DataFrame.from_items([(names[i], matched_all[:, i]) for i in order])\n",
    "    sb.boxplot(data=df)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_single(names, models, angles, test_id):\n",
    "    all_probs, all_matched = compare(test_id, angles, models)\n",
    "    legends = []\n",
    "\n",
    "    order = np.argsort(all_matched)\n",
    "    for i in order:\n",
    "        plt.plot(angles, all_probs[i])\n",
    "        legends.append('{} {:.2f}%'.format(names[i], all_matched[i]))\n",
    "\n",
    "    plt.ylabel('Prediction probability of correct class')\n",
    "    plt.legend(legends, loc=9, bbox_to_anchor=(0.5, -0.05), ncol=len(names))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    names = ['baseline', '8_rot_4', '8_rot_3', '8_rot_2', '8_rot_1', '4_rot_4', '4_rot_3', '4_rot_2', '4_rot_1']\n",
    "    convs = [\n",
    "        None,\n",
    "        [conv_8, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_8, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_8, conv_8],\n",
    "        [conv_old, conv_old, conv_old, conv_8],\n",
    "        [conv_4, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_4, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_4, conv_4],\n",
    "        [conv_old, conv_old, conv_old, conv_4],\n",
    "    ]\n",
    "\n",
    "    models = []\n",
    "    indices = range(len(names))\n",
    "    for i in indices:\n",
    "        model = get_model(convs[i])\n",
    "        model.load_weights('./weights/{}.hdf5'.format(names[i]))\n",
    "        models.append(model)\n",
    "\n",
    "    angles = np.arange(0, 360, 1)\n",
    "    # plot_single([names[i] for i in indices], models, angles=angles, test_id=5)\n",
    "    plot_multi(names, models, angles=angles, runs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
